tion learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the smallmodel's capability as they tend to learn to imitate the style, but not the reasoning process of LFMs. To address these challenges, we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMA's release policy to be published at this https URL), a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT. To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like theSAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve modelcapabilities and skills.OpenChatKithttps://www.together.xyz/blog/openchatkithttps://huggingface.co/spaces/togethercomputer/OpenChatKithttps://github.com/togethercomputer/OpenChatKitOpenChatKit uses a 20 billion parameter chat model trained on 43 million instructions and supports reasoning, multi-turn conversation, knowledge and generative answers.OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications. Thekit includes an instruction-tuned 20 billion parameter language model, a 6 billion parameter moderation model, and an extensible retrievalsystem for including up-to-date responses from custom repositories. It was trained on the OIG-43M training dataset, which was a collaboration between Together, LAION, and Ontocord.ai. Much more than a model release, this is the beginning of an open source project. We arereleasing a set of tools and processes for ongoing improvement with community contributions.Open-Assistanthttps://github.com/LAION-AI/Open-Assistanthttps://open-assistant.io/zhOpen Assistant is a project meant to give everyone access to a great chat based large language model.We believe that by doing this we will create a revolution in innovation in language. In the same way that stable-diffusion helped the world make art and images in new ways we hope Open Assistant can help improve the world by improving language itself.MedLLaMA-13B & PMC-LLaMA: Continue Training LLaMA on Medical Papershttps://github.com/chaoyi-wu/PMC-LLaMAhttps://huggingface.co/chaoyi-wu/PMC_LLAMA_7Bhttps://arxiv.org/abs/2304.14454We have release a new model MedLLaMA-13B finetuned with LLaMA-13B on some medical corpus, termed as MedLLaMA-13B. It have been proved to be more powerful than both LLaMA-13B and PMC-LLaMA, refering to our benchmark for detail comparison.RedPajama（可商⽤）https://www.together.xyz/blog/redpajamahttps://github.com/togethercomputer/RedPajama-DataRedPajama, a project to create leading open-source models, starts by reproducing LLaMA training dataset of over 1.2 trillion tokens.StableLMhttps://zhuanlan.zhihu.com/p/623542189https://github.com/Stability-AI/StableLMStableLM: Stability AI Language ModelsThis repository contains Stability AI's ongoing development of the StableLM series of language models and will be continuously updated with new checkpoints. The following provides an overview of all currently available models. More coming soon.StableVicunahttps://github.com/Stability-AI/StableLMStableVicuna基于⼩⽺驼Vicuna-13B的进⼀步指令微调和RLHF训练的版本。
Vicuna-13B是LLaMA-13B的⼀个指令微调模型。
Stanford Alpacahttps://crfm.stanford.edu/2023/03/13/alpaca.htmlhttps://alpaca-ai.ngrok.io/https://github.com/tatsu-lab/stanford_alpacaAlpaca: A Strong, Replicable Instruction-Following ModelAlWe introduce Alpaca 7B, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. On our preliminary evaluation of single-turn instruction following, Alpaca behaves qualitatively similarly to OpenAI’s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (<600$).UltraLM-13Bhttps://github.com/thunlp/UltraChatUltraLM is a series of chat language models trained on UltraChat. Currently, we have released the 13B version, which ranks #1 among open-source models and ranks #4 among all models on AlpacaEval Leaderboard. UltraLM-13B is based upon LLaMA-13B.This project aims to construct open-source, large-scale, and multi-round dialogue data powered by Turbo APIs to facilitate the construction of powerful language models with general conversational capability. In consideration of factors such as safeguarding privacy, we do not directly use any data available on the Internet as prompts. To ensure generation quality, two separate ChatGPT Turbo APIs are adopted in generation, where one plays the role of the user to generate queries and the other generates the response. We instruct the user model with carefully designed prompts to mimic human user behavior and call the two APIs iteratively. The generated dialogues undergo further post-processing and filtering.Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Qualityhttps://chat.lmsys.org/https://vicuna.lmsys.org/https://github.com/lm-sys/FastChatAn open platform for training, serving, and evaluating large language model based chatbots.Wombathttps://mp.weixin.qq.com/s/xoPKmOzjlNZ2qGdcKeGARwhttps://mp.weixin.qq.com/s/UI-ij5o43ct1efYoNVdQDghttps://arxiv.org/abs/2304.05302v1https://github.com/GanjinZero/RRHFThis is the repository for RRHF (Rank Response to align Human Feedback) and open-sourced language models Wombat. RRHF helps alignlarge language models with human perference easier.Reinforcement Learning from Human Feedback (RLHF) enables the alignment of large language models with human preference, improvingthe quality of interactions between humans and language models. Recent practice of RLHF uses PPO to enable the large language model optimization of such alignment. However, implementing PPO is non-trivial (where the training procedure requires interactive between policy,behavior policy, reward, value model) and it is also tedious to tuning many hyper-parameters. Our motivation is to simplify the alignment between language models with human preference, and our proposed paradigm RRHF (Rank Response from Human Feedback) can achieve such alignment as easily as conventional fine-tuning. It is simpler than PPO from the aspects of coding, model counts, and hyperparameters.XGen-7Bhttps://blog.salesforceairesearch.com/xgen/https://github.com/salesforce/xgenWe trained a series of 7B LLMs named XGen-7B with standard dense attention on up to 8K sequence length for up to 1.5T tokens. We alsofine tune the models on public-domain instructional data. The main take-aways are:On standard NLP benchmarks, XGen achieves comparable or better results when compared with state-of-the-art open-source LLMs (e.g. MPT, Falcon, LLaMA, Redpajama, OpenLLaMA) of similar model size.Our targeted evaluation on long sequence modeling benchmarks show benefits of our 8K-seq models over 2K- and 4K-seq models.XGen-7B archives equally strong results both in text (e.g., MMLU, QA) and code (HumanEval) tasks.Training cost of $150K on 1T tokens under Google Cloud pricing for TPU-v4.4 评价天秤（FlagEval）https://flageval.baai.ac.cn/#/home⼤语⾔评测体系及开放平台：构建“能⼒-任务-指标”三维评测框架，细粒度刻画模型的认知能⼒边界。
獬⾘（Xiezhi）Benchmarkhttps://arxiv.org/abs/2306.05783https://github.com/MikeGu721/XiezhiBenchmarkXiezhi是⼀个综合的、多学科的、能够⾃动更新的领域知识评估Benchmark。
Xiezhi包含了哲学、经济学、法学、教育学、⽂学、历史学、⾃然科学、⼯学、农学、医学、军事学、管理学、艺术学这13个学科⻔类，24万道学科题⽬，516个具体学科，249587道题⽬。
这 516 个学科以及分类⽅式源⾃中国教育部颁布的学科分类法。
作者从中国研究⽣⼊学考试中⼿动选择并注释了 20,000 道多选题，涵盖了这 516 个标签，以形成Xiezhi-Meta数据集。
Xiezhi-Meta被⽤来训练⼀个能够计算题⽬和学科标签之间相关性的标注模型。
作者们随后收集了来⾃不同考试的 150,000 个多项选择题，以及来⾃学术Survey的 70,000 个多项选择题，并使⽤标注模型对所有这些问题进⾏了注释。
为了⽅便进⾏实验，并能够有效地评估LLM对于跨学科知识的处理能⼒，作者们提出了Xiezhi-Specialty和Xiezhi-Interdiscipline，这两个数据集都提供了中英⽂的版本，并由 15,000 个更平衡、更不敏感、更不以中国为中⼼的多选题组成。
 Xiezhi-Specialty 包含可以使⽤单⼀领域的知识解决的问题，⽽ Xiezhi-Interdiscipline 包含需要来⾃多个领域的知识才能解决的问题。
C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Modelshttps://arxiv.org/abs/2305.08322https://cevalbenchmark.com/https://github.com/SJTU-LIT/cevalC-Eval is a comprehensive Chinese evaluation suite for foundation models. It consists of 13948 multi-choice questions spanning 52 diverse disciplines and four difficulty levels.HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Modelshttps://mp.weixin.qq.com/s/cuoO2V4X-GQOuWyA-e9BeQhttps://arxiv.org/abs/2305.11747https://github.com/RUCAIBox/HaluEval为了进⼀步研究⼤模型幻象的内容类型和⼤模型⽣成幻象的原因，本⽂提出了⽤于⼤语⾔模型幻象评估的基准⸺HaluEval。
我们基于现有的数据集，通过⾃动⽣成和⼿动标注的⽅式构建了⼤量的幻象数据组成HaluEval的数据集，其中包含特定于问答、对话、⽂本摘要任务的30000条样本以及普通⽤户查询的5000条样本。
在本⽂中，我们详细介绍了HaluEval数据集的构建过程，对构建的数据集进⾏了内容分析，并初步探索了⼤模型识别和减少幻象的策略。
KoLA: Carefully Benchmarking World Knowledge of Large Language Modelshttps://mp.weixin.qq.com/s/xVj1blhRtpO-Y1HgQ8Wl-Ahttps://arxiv.org/pdf/2306.09296.pdfhttps://kola.xlore.cnKoLA基于19个关注实体、概念和事件的任务。
参考了Bloom认知体系，KoLA从知识的记忆、理解、应⽤和创造4个层级，从深度⽽⾮⼴度去衡量⼤语⾔模型处理世界知识的能⼒。
实验结果表明，GPT-4虽然很强，但依然未能霸榜，在知识创造层次的测试中仅排第三名。
Multiscale Positive-Unlabeled Detection of AI-Generated Textshttps://mp.weixin.qq.com/s/KBN8TMwXD1bcE2X_dImXVghttps://arxiv.org/abs/2305.18149https://github.com/mindspore-lab/mindone/tree/master/examples/detect_chatgpthttps://github.com/YuchuanTian/AIGC_text_detectorRecent releases of Large Language Models (LLMs), e.g. ChatGPT, are astonishing at generating human-like texts, but they may get misused for fake scholarly texts, fake news, fake tweets, et cetera. Previous works have proposed methods to detect these multiscale AI-generated texts, including simple ML classifiers, pretrained-model-based training-agnostic methods, and finetuned language classification models.However, mainstream detectors are formulated without considering the factor of corpus length: shorter corpuses are harder to detect compared with longer ones for shortage of informative features. In this paper, a Multiscale Positive-Unlabeled (MPU) training framework is proposed to address the challenge of multiscale text detection. Firstly, we acknowledge the human-resemblance property of short machine texts, and rephrase text classification as a Positive-Unlabeled (PU) problem by marking these short machine texts as "unlabeled" during training. In this PU context, we propose the length-sensitive Multiscale PU Loss, where we use a recurrent model in abstraction to estimate positive priors of scale-variant corpuses. Additionally, we introduce a Text Multiscaling module to enrich training corpuses. Experiments showthat our MPU method augments detection performance on long AI-generated text, and significantly improves short-corpus detection of language model detectors. Language Models trained with MPU could outcompete existing detectors by large margins on multiscale AI-generated texts.PandaLMhttps://github.com/WeOpenML/PandaLMhttps://zhuanlan.zhihu.com/p/630173415https://mp.weixin.qq.com/s/HE6jez3G9aEO5qLkvwtKXgThis is the official repository for PandaLM: ReProducible and Automated Language Model Assessment.PandaLM aims to provide reproducible and automated comparisons between different large language models (LLMs). By giving PandaLM the same context, it can compare the responses of different LLMs and provide a reason for the decision, along with a reference answer. Thetarget audience for PandaLM may be organizations that have confidential data and research labs with limited funds that seek reproducibility. These organizations may not want to disclose their data to third parties or may not be able to afford the high costs of secret data leakage using third-party APIs or hiring human annotators. With PandaLM, they can perform evaluations without compromising data security or incurring high costs, and obtain reproducible results. To demonstrate the reliability and consistency of our tool, we have created a diverse human-annotated test dataset of approximately 1,000 samples, where the contexts and the labels are all created by humans. On our test dataset, PandaLM-7B has achieved 94% ChatGPT's evaluation ability in terms of accuracy. The papers and more features are coming soon.5 其它Alpaca-CoThttps://github.com/PhoebusSi/Alpaca-CoThttps://mp.weixin.qq.com/s/Q5Q3RpQ80XmpbfhSxq2R1QAn Instruction Fine-Tuning Platform with Instruction Data Collection and Unified Large Language Models InterfaceAlpaca-CoT项⽬旨在探究如何更好地通过instruction-tuning的⽅式来诱导LLM具备类似ChatGPT的交互和instruction-following能⼒。
为此，我们⼴泛收集了不同类型的instruction（尤其是Chain-of-Thought数据集），并基于LLaMA给出了深⼊细致的实证研究，以供未来⼯作参考。
据我们所知，我们是⾸个将CoT拓展进Alpaca的⼯作，因此简称为"Alpaca-CoT"。
Auto-GPThttps://github.com/torantulino/auto-gptAuto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven byGPT-4, chains together LLM "thoughts", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI.ChatPiXiuhttps://github.com/catqaq/ChatPiXiu我们是羡⻥智能【xianyu.ai】，主要成员是⼀群来⾃⽼和⼭下、⻄湖边上的咸⻥们，塘主叫作羡⻥，想在LLMs时代做点有意义的事！我们的⼝号是：做OpenNLP和OpenX！希望在CloseAI卷死我们之前退出江湖！也许有⼀天，等到GPT-X发布的时候，有⼈会说NLP不存在了，但是我们想证明有⼈曾经来过、热爱过！在以ChatGPT/GPT4为代表的LLMs时代，在被CloseAI卷死之前，我们发起了OpenNLP计划，宗旨是OpenNLP for everyone!ChatPiXiu项⽬为OpenNLP计划的第2个正式的开源项⽬，旨在Open ChatGPT for everyone！在以ChatGPT/GPT4为代表的LLMs时代，在被OpenAI卷死之前，做⼀点有意义的事情！未来有⼀天，等到GPT-X发布的时候，或许有⼈会说NLP不存在了，但是我们想证明有⼈曾来过！Gorillahttps://mp.weixin.qq.com/s/p9tx3q3Lpr4fNqdyxWhzyAgorilla.cs.berkeley.eduarxiv.org/abs/2305.15334https://github.com/ShishirPatil/gorilla/⼤型语⾔模型性能强⼤，但为了更好地⽤于解决实际问题，各式各样的 API 是必不可少的。
加利福尼亚⼤学伯克利分校和微软研究院造出了⼀只「⼤猩猩」Gorilla，该模型能根据⽤户输⼊的⾃然语⾔为⽤户选择合适的 API 来执⾏对应任务。
理论上讲，这个模型可以根据⽤户需求调⽤其它各种 AI 模型，因此 Gorilla 有望成为⼀个统御其它 AI 的 AI 模型。
该项⽬的代码、模型、数据和演示都已发布。
HuggingGPThttps://mp.weixin.qq.com/s/o51CmLt2JViJ4nsKfBJfwghttps://arxiv.org/pdf/2303.17580.pdfHuggingGPT利⽤ChatGPT作为控制器，连接HuggingFace社区中的各种AI模型，来完成多模态复杂任务。
这意味着，你将拥有⼀种超魔法，通过HuggingGPT，便可拥有多模态能⼒，⽂⽣图、⽂⽣视频、语⾳全能拿捏了。
LLMPruner：⼤语⾔模型裁剪⼯具https://mp.weixin.qq.com/s/u0UcCxzJOkF4fO_JI6ToQAhttps://github.com/yangjianxin1/LLMPruner在许多下游任务中，我们往往只需要使⽤到⼀两种语⾔，例如在中⽂场景中，⼀般只会⽤到中英⽂。
 所以我们可以对⼤语⾔模型的词表进⾏裁剪，只留下所需的部分词表，这样不仅能够充分保留模型的预训练知识，并且减少模型参数量，降低显存占⽤，提升训练速度，使⽤更少的显卡进⾏下游任务的finetune训练。
基于上述原因，笔者开发了LLMPruner项⽬，⽬前主要包含裁剪后的各种参数规模的Bloom模型。
对Bloom进⾏词表裁剪，保留常⽤的中英⽂token，词表由250880将⾄46145，缩减为原来的18.39%。
LLM-Pruner: On the Structural Pruning of Large Language Modelshttps://github.com/horseee/LLM-Prunerhttps://arxiv.org/abs/2305.11627https://mp.weixin.qq.com/s/feqFfy4n31eztoZfodMieQ在本⽂中，我们提出了 LLM-Pruner，⼀种⽤于⼤型语⾔模型的结构化剪枝⽅法。
LLM-Pruner 旨在以任务⽆关的⽅式压缩庞⼤的语⾔模型，同时尽量减少对原始训练语料库的依赖，并保留 LLM 的语⾔能⼒。
LLM-Pruner 通过迭代地检查模型中的每个神经元作为识别依赖组的触发器，从⽽构建 LLM 的依赖图。
随后，LLM-Pruner 使⽤参数级和权重级估计来评估这些组的重要性。
最后，我们利⽤ LoRA 对被剪枝模型进⾏快速恢复和调整。
我们使⽤多个 zero-shot 数据集评估了 LLM-Pruner 在三个不同模型（LLaMA，Vicuna 和 ChatGLM）上的有效性。
我们的实验结果表明，LLM-Pruner 成功地剪枝了模型，在保留 zero-shot 能⼒的同时减轻了计算负担。
LLM for Recommendation Systemshttps://github.com/WLiK/LLM4Rechttps://arxiv.org/abs/2305.19860https://mp.weixin.qq.com/s/WCUjCahiak4STbb0QjJInQLarge Language Models (LLMs) have emerged as powerful tools in the field of Natural Language Processing (NLP) and have recently gained significant attention in the domain of Recommendation Systems (RS). These models, trained on massive amounts of data using self-supervised learning, have demonstrated remarkable success in learning universal representations and have the potential to enhance various aspects of recommendation systems by some effective transfer techniques such as fine-tuning and prompt tuning, and so on. The crucial aspect of harnessing the power of language models in enhancing recommendation quality is the utilization of their high-quality representations of textual features and their extensive coverage of external knowledge to establish correlations between items and users. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey presents a taxonomy that categorizes thesemodels into two major paradigms, respectively Discriminative LLM for Recommendation (DLLM4Rec) and Generative LLM for Recommendation (GLLM4Rec), with the latter being systematically sorted out for the first time. Furthermore, we systematically review and analyze existing LLM-based recommendation systems within each paradigm, providing insights into their methodologies, techniques, and performance. Additionally, we identify key challenges and several valuable findings to provide researchers and practitioners with inspiration.Self-Instructhttps://github.com/yizhongw/self-instructhttps://arxiv.org/abs/2212.10560Self-Instruct is a framework that helps language models improve their ability to follow natural language instructions. It does this by using the model's own generations to create a large collection of instructional data. With Self-Instruct, it is possible to improve the instruction-following capabilities of language models without relying on extensive manual annotation.ToolBenchhttps://github.com/OpenBMB/ToolBenchhttps://arxiv.org/pdf/2304.08354.pdfhttps://mp.weixin.qq.com/s/DuoQJj1OBl5iFPvjidDiCgThis project aims to construct open-source, large-scale, high-quality instruction tuning SFT data to facilitate the construction of powerfulLLMs with general tool-use capability. We provide the dataset, the corresponding training and evaluation scripts, and a capable model ToolLLaMA fine-tuned on ToolBench.Wanda (Pruning by Weights and activations)https://github.com/locuslab/wandahttps://mp.weixin.qq.com/s/UoQLCQiFnKZUQPedDM_MCQhttps://arxiv.org/pdf/2306.11695.pdfA Simple and Effective Pruning Approach for Large Language ModelsAs their size increases, Large Languages Models (LLMs) are natural candidates for network pruning methods: approaches that drop a subset of network weights while striving to preserve performance. Existing methods, however, require either retraining, which is rarely affordable for billion-scale LLMs, or solving a weight reconstruction problem reliant on second-order information, which may also be computationally expensive. In this paper, we introduce a novel, straightforward yet effective pruning method, termed Wanda (Pruning by Weights and activations), designed to induce sparsity in pretrained LLMs. Motivated by the recent observation of emergent large magnitude features in LLMs, our approach prune weights with the smallest magnitudes multiplied by the corresponding input activations, on a per-output basis. Notably, Wanda requires no retraining or weight update, and the pruned LLM can be used as is. We conduct a thorough evaluation of our method on LLaMA across various language benchmarks. Wanda significantly outperforms the established baseline of magnitude pruning and competes favorably against recent methods involving intensive weight update.本⽂档由⽹友提供，仅限参考学习，如有不妥或产⽣版权问题，请联系我们及时删除。
 客服请联系：31998589@qq.com 微信：skillupvip这个创作者的更多内容查看更多检索增强⽣成 (RAG):What, Why a 为什么说数智化可以帮助中⼩企业 ChatGPT提示⼯程5篇合集 - 吴恩nd How? 降本增效 ? 达和OpenAI出品评论0 评论关于我们 ⽤户协议京ICP备20027199号-1