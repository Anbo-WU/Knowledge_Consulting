⾸⻚ AI资讯 聊天魔法 图⽚魔法 写作魔法 ⾳视频魔法 编程魔法 开源训练国内外开源⼤语⾔模型⼀览表20秒读懂全⽂国内外开源⼤语⾔模型⼀览表国内外开源⼤语⾔模型⼀览表2023-07-19 收藏 分享⼤模型1 Chinese Open Source Language Models本草推荐阅读https://zhuanlan.zhihu.com/p/626536996· 最新最全的开源中⽂⼤语⾔模型列表https://github.com/scir-hi/huatuo-llama-med-chinese· 链接⼤模型与外部知识，智源开源最强语义基于中⽂医学知识的LLaMa指令微调模型 向量模型BGE在⽣物医学领域，LLM模型（如LLaMa，ChatGLM）因为缺乏⼀定的医学专业知识语料⽽表现不佳。
该项⽬通过医学知识图谱和GPT3.5API · Chinese-LLM开源中⽂⼤语⾔模型合集构建了中⽂医学指令数据集，并对LLaMa模型进⾏了指令微调得到了⼀个针对医学领域的智能问诊模型HuaTuo，相⽐于未经过医学数据指令· 开源语⾳⼤语⾔模型来了！阿⾥基于Qwen-微调的原LLaMa⽽⾔，HuaTuo模型在智能问诊层⾯表现出⾊，可⽣成⼀些更为可靠的医学知识回答；与此同时，基于相同医学数据，该项⽬Chat提出Qwen-Audio!还训练了医疗版本的ChatGLM模型: ChatGLM-6B-Med，· 国内开源的低代码框架有哪些？该团队还即将发布扁鹊模型PienChueh(同为基于医学数据训练的⼤模型)，欢迎⼤家届时使⽤体验。
· 国外报告90%的AI类产品公司已经实现盈利百川 Baichuan-7B ，⽽国内⼤模型和AIGC的访谈说太卷了https://github.com/baichuan-inc/baichuan-7B · ⼀个专业级 AI 聊天浏览器，开源了！https://huggingface.co/baichuan-inc/baichuan-7Bbaichuan-7B 是由百川智能开发的⼀个开源可商⽤的⼤规模预训练语⾔模型。
基于 Transformer 结构，在⼤约1.2万亿 tokens 上训练的70亿参数模型，⽀持中英双语，上下⽂窗⼝⻓度为4096。
在标准的中⽂和英⽂权威 benchmark（C-EVAL/MMLU）上均取得同尺⼨最好的效果。
原始数据包括开源的中英⽂数据和⾃⾏抓取的中⽂互联⽹数据，以及部分⾼质量知识性数据。
参考相关数据⼯作，频率和质量是数据处理环节重点考虑的两个维度。
 我们基于启发式规则和质量模型打分，对原始数据集进⾏篇章和句⼦粒度的过滤。
在全量数据上，利⽤局部敏感哈希⽅法，对篇章和句⼦粒度做滤重。
百川 Baichuan-13B（可商⽤）https://githuB.com/Baichuan-inc/Baichuan-13B更⼤尺⼨、更多数据:Baichuan-13B 在 Baichuan-7B 的基础上进⼀步扩⼤参数量到130亿，并且在⾼质量的语料上训练了1.4万亿 tokens，超过 LLaMA-13B40%，是当前开源13B 尺⼨下训练数据量最多的模型。
⽀持中英双语，使⽤ ALiBi 位置编码，上下⽂窗⼝⻓度为4096。
同时开源预训练和对⻬模型:预训练模型是适⽤开发者的『 基座 』，⽽⼴⼤普通⽤户对有对话功能的对⻬模型具有更强的需求。
因此本次开源我们同时发布了对⻬模型（Baichuan-13B-Chat），具有很强的对话能⼒，开箱即⽤，⼏⾏代码即可简单的部署。
更⾼效的推理:为了⽀持更⼴⼤⽤户的使⽤，我们本次同时开源了 int8和 int4的量化版本，相对⾮量化版本在⼏乎没有效果损失的情况下⼤⼤降低了部署的机器资源⻔槛，可以部署在如 Nvidia3090这样的消费级显卡上。
开源免费可商⽤:Baichuan-13B 不仅对学术研究完全开放，开发者也仅需邮件申请并获得官⽅商⽤许可后，即可以免费商⽤。
华佗https://mp.weixin.qq.com/s/lwJb8N420xfMTvXJPM2gtghttps://arxiv.org/pdf/2305.15075.pdfhttps://github.com/FreedomIntelligence/HuatuoGPThttps://www.huatuogpt.cn/该论⽂提出的语⾔模型训练⽅法可以结合医⽣和 ChatGPT 的数据，充分发挥它们的互补作⽤，既保留真实医疗数据的专业性和准确性，⼜借助 ChatGPT 的多样性和内容丰富性的特点。
扁鹊https://github.com/scutcyr/BianQue基于主动健康的主动性、预防性、精确性、个性化、共建共享、⾃律性六⼤特征，华南理⼯⼤学未来技术学院-⼴东省数字孪⽣⼈重点实验室开源了中⽂领域⽣活空间主动健康⼤模型基座ProactiveHealthGPT，包括：经过千万规模中⽂健康对话数据指令微调的⽣活空间健康⼤模型扁鹊（BianQue）经过百万规模⼼理咨询领域中⽂⻓⽂本指令与多轮共情对话数据联合指令微调的⼼理健康⼤模型灵⼼（SoulChat）我们期望，⽣活空间主动健康⼤模型基座ProactiveHealthGPT 可以帮助学术界加速⼤模型在慢性病、⼼理咨询等主动健康领域的研究与应⽤。
本项⽬为 ⽣活空间健康⼤模型扁鹊（BianQue） 。
灵⼼（SoulChat）https://github.com/scutcyr/SoulChat我们调研了当前常⻅的⼼理咨询平台，发现，⽤户寻求在线⼼理帮助时，通常需要进⾏较⻓篇幅地进⾏⾃我描述，然后提供帮助的⼼理咨询师同样地提供⻓篇幅的回复，缺失了⼀个渐进式的倾诉过程。
但是，在实际的⼼理咨询过程当中，⽤户和⼼理咨询师之间会存在多轮次的沟通过程，在该过程当中，⼼理咨询师会引导⽤户进⾏倾诉，并且提供共情，例如：“⾮常棒”、“我理解你的感受”、“当然可以”等等。
考虑到当前⼗分⽋缺多轮共情对话数据集，我们⼀⽅⾯，构建了超过15万规模的 单轮⻓⽂本⼼理咨询指令与答案（SoulChatCorpus-single_turn） ，回答数量超过50万（指令数是当前的常⻅的⼼理咨询数据集 PsyQA 的6.7倍），并利⽤ChatGPT与GPT4，⽣成总共约100万轮次的多轮回答数据（SoulChatCorpus-multi_turn） 。
特别地，我们在预实验中发现，纯单轮⻓本⽂驱动的⼼理咨询模型会产⽣让⽤户感到厌烦的⽂本⻓度，⽽且不具备引导⽤户倾诉的能⼒，纯多轮⼼理咨询对话数据驱动的⼼理咨询模型则弱化了模型的建议能⼒，因此，我们混合SoulChatCorpus-single_turn和SoulChatCorpus-multi_turn构造成超过120万个样本的 单轮与多轮混合的共情对话数据集SoulChatCorpus 。
所有数据采⽤“⽤户：xxx\n⼼理咨询师：xxx\n⽤户：xxx\n⼼理咨询师：”的形式统⼀为⼀种指令格式。
我们选择了 ChatGLM-6B 作为初始化模型，进⾏了全量参数的指令微调，旨在提升模型的共情能⼒、引导⽤户倾诉能⼒以及提供合理建议的能⼒。
更多训练细节请留意我们后续发布的论⽂。
启真医学⼤模型https://github.com/CMKRG/QiZhenGPT本项⽬利⽤启真医学知识库构建的中⽂医学指令数据集，并基于此在Chinese-LLaMA-Plus-7B、CaMA-13B、ChatGLM-6B模型上进⾏指令精调，⼤幅提⾼了模型在中⽂医疗场景下效果，⾸先针对药品知识问答发布了评测数据集，后续计划优化疾病、⼿术、检验等⽅⾯的问答效果，并针对医患问答、病历⾃动⽣成等应⽤展开拓展。
【貔貅】FinMA & PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Financehttps://github.com/chancefocus/PIXIUhttps://arxiv.org/abs/2306.05443https://huggingface.co/spaces/ChanceFocus/FLAREThe advancement of Natural Language Processing (NLP) and machine learning (ML) techniques in financial technology (FinTech) has enabled a diverse set of capabilities from predicting stock price movements to advanced financial analytics. However, to effectively understand the complex financial language and concepts, domain-specific LLMs are necessary.Despite prior efforts, there is a lack of open-source financial LLMs and benchmarks to evaluate them. Additionally, these models are not fine-tuned to follow natural language instructions, limiting their performance in downstream financial tasks.To address these gaps, we introduce PIXIU, providing:Open-source LLMs tailored for finance called FinMA, by fine-tuning LLaMA with the dataset constructed in PIXIU.Large-scale, high-quality multi-task and multi-modal financial instruction tuning data FIT.Holistic financial evaluation benchmarks FLARE for assessing financial LLMs.Key FeaturesOpen resources: PIXIU openly provides the financial LLM, instruction tuning data, and datasets included in the evaluation benchmark to encourage open research and transparency.Multi-task: The instruction tuning data in PIXIU cover a diverse set of financial tasks, including four financial NLP tasks and one financial prediction task.Multi-modality: PIXIU's instruction tuning data consist of multi-modality financial data, including time series data from the stock movement prediction task. It covers various types of financial texts, including reports, news articles, tweets, and regulatory filings.Diversity: Unlike previous benchmarks focusing mainly on financial NLP tasks, PIXIU's evaluation benchmark includes critical financialprediction tasks aligned with real-world scenarios, making it more challenging.中⽂Alpaca模型Luotuohttps://sota.jiqizhixin.com/project/luotuohttps://github.com/LC1332/Luotuo-Chinese-LLMAlpaca 是斯坦福团队基于 LLaMA 7B 在 52k 指令上微调得到的模型，能出⾊适应多种⾃然语⾔应⽤场景。
近⽇来⾃商汤科技和华中科技⼤学开源中⽂语⾔模型 Luotuo，基于 ChatGPT API 翻译 Alpaca 微调指令数据，并使⽤ lora 进⾏微调得到。
⽬前该项⽬已公开训练的语料和模型权重⽂件（两个型号），供开发者可使⽤⾃⼰各种⼤⼩的语料，训练⾃⼰的语⾔模型，并适⽤到对应的垂直领域。
中⽂LLaMA&Alpaca⼤模型https://github.com/ymcui/Chinese-LLaMA-Alpaca以ChatGPT、GPT-4等为代表的⼤语⾔模型（Large Language Model, LLM）掀起了新⼀轮⾃然语⾔处理领域的研究浪潮，展现出了类通⽤⼈⼯智能（AGI）的能⼒，受到业界⼴泛关注。
然⽽，由于⼤语⾔模型的训练和部署都极为昂贵，为构建透明且开放的学术研究造成了⼀定的阻碍。
为了促进⼤模型在中⽂NLP社区的开放研究，本项⽬开源了中⽂LLaMA模型和经过指令精调的Alpaca⼤模型。
这些模型在原版LLaMA的基础上扩充了中⽂词表并使⽤了中⽂数据进⾏⼆次预训练，进⼀步提升了中⽂基础语义理解能⼒。
同时，在中⽂LLaMA的基础上，本项⽬使⽤了中⽂指令数据进⾏指令精调，显著提升了模型对指令的理解和执⾏能⼒。
中⽂对话式⼤语⾔模型Fireflyhttps://mp.weixin.qq.com/s/tyH9Ifcvw4DKqoIoYjT6Kghttps://github.com/yangjianxin1/FireflyFirefly（流萤） 是⼀个开源的中⽂对话式⼤语⾔模型，使⽤指令微调（Instruction Tuning）在中⽂数据集上进⾏调优。
同时使⽤了词表裁剪、ZeRO、张量并⾏等技术，有效降低显存消耗和提⾼训练效率。
 在训练中，我们使⽤了更⼩的模型参数量，以及更少的计算资源。
我们构造了许多与中华⽂化相关的数据，以提升模型这⽅⾯的表现，如对联、作诗、⽂⾔⽂翻译、散⽂、⾦庸⼩说等。
凤凰https://mp.weixin.qq.com/s/beAAh_MdqssV8bEKsccElghttps://github.com/FreedomIntelligence/LLMZooLLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.【复旦】MOSShttps://github.com/OpenLMLab/MOSShttps://mp.weixin.qq.com/s/LjToZVWjQ-ot5KJFCFtA3gMOSS是⼀个⽀持中英双语和多种插件的开源对话语⾔模型，moss-moon系列模型具有160亿参数，在FP16精度下可在单张A100/A800或两张3090显卡运⾏，在INT4/8精度下可在单张3090显卡运⾏。
MOSS基座语⾔模型在约七千亿中英⽂以及代码单词上预训练得到，后续经过对话指令微调、插件增强学习和⼈类偏好训练具备多轮对话能⼒及使⽤多种插件的能⼒。
【复旦】MOSS-RLHFhttps://mp.weixin.qq.com/s/BjXtnEEVCQiPOy-_qCNM4ghttps://openlmlab.github.io/MOSS-RLHF/paper/SecretsOfRLHFPart1.pdfhttps://openlmlab.github.io/MOSS-RLHF/FudanNLP 团队通过⼤量、详实⼯作，设计实验充分探索了⼤模型 RLHF 的完整⼯作流程，仔细剖析了 RLHF 中的强化学习 PPO 算法的内部⼯作原理以及它在整个 RLHF 中的作⽤，并研究各种优化⽅法如何影响训练过程。
通过这些努⼒，确定了使得 PPO 算法在⼤模型⼈类对⻬⽅⾯⾏之有效的关键因素。
综合上述发现，该团队进⼀步总结出在⼤模型上训练更稳定的 PPO 算法版本：PPO-max。
并使⽤ Helpful 和 Harmless 数据集全⾯评估，结果显示经过 PPO-max 算法训练的模型展现出了出⾊的⼈类对⻬性能！综合上述发现，该团队进⼀步总结出在⼤模型上训练更稳定的 PPO 算法版本：PPO-max。
并使⽤ Helpful 和 Harmless 数据集全⾯评估，结果显示经过 PPO-max 算法训练的模型展现出了出⾊的⼈类对⻬性能！【度⼩满】轩辕-⾸个千亿级中⽂⾦融对话模型https://arxiv.org/pdf/2305.12002.pdfhttps://huggingface.co/xyz-nlp/XuanYuan2.0https://github.com/Duxiaoman-DI/XuanYuanhttps://huggingface.co/xyz-nlp/XuanYuan2.0https://zhuanlan.zhihu.com/p/632780608轩辕是国内⾸个开源的千亿级中⽂对话⼤模型，同时也是⾸个针对中⽂⾦融领域优化的千亿级开源对话⼤模型。
轩辕在BLOOM-176B的基础上针对中⽂通⽤领域和⾦融领域进⾏了针对性的预训练与微调，它不仅可以应对通⽤领域的问题，也可以解答与⾦融相关的各类问题，为⽤户提供准确、全⾯的⾦融信息和建议。
悟道·天鹰（Aquila）https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila这是⾸个具备中英双语知识、⽀持商⽤许可协议、⽀持国内数据合规要求的开源语⾔⼤模型。
悟道·天鹰（Aquila）系列模型包括 Aquila基础模型（7B、33B），AquilaChat对话模型（7B、33B）以及 AquilaCode “⽂本-代码”⽣成模型。
桃李：国际中⽂教育⼤模型https://github.com/blcuicall/taoli随着ChatGPT引起全社会的关注，及各类⼤语⾔模型（Large Language Model）争相亮相，通⽤领域⾃然语⾔处理任务已获得巨⼤成功，引起了国际中⽂教育领域的普遍关注。
国际中⽂教育⼈⼠纷纷展开了对⼤模型的探讨： ⼤模型是否可以根据学习者的⽔平，提供合适的语⾔表达，或根据学习者的问题给出详细的解答，从⽽在⼀定程度上辅助甚⾄充当学习伙伴、语⾔教师？ 然⽽，⽬前通⽤领域的⼤模型在垂直领域的效果仍有限。
为解决上述问题，我们全⾯推出适⽤于国际中⽂教育领域的⼤模型 “桃李”（Taoli）1.0 ，⼀个在国际中⽂教育领域数据上进⾏了额外训练的模型。
我们基于⽬前国际中⽂教育领域流通的500余册国际中⽂教育教材与教辅书、汉语⽔平考试试题以及汉语学习者词典等，构建了国际中⽂教育资源库。
 我们设置了多种形式的指令来充分利⽤知识，构造了共计 88000 条的⾼质量国际中⽂教育问答数据集，并利⽤收集到的数据对模型进⾏指令微调，让模型习得将法律知识应⽤到具体场景中的能⼒。
情感⼤模型PICAhttps://mp.weixin.qq.com/s/E37EFe10185THHa3pSqBighttps://github.com/NEU-DataMining/PICAhttps://huggingface.co/NEUDM/PICA-V1PICA 以清华⼤学开源的ChatGLM2-6B为基础，采⽤Prompt tuning技术在4 卡 A6000 训练⼤约15个⼩时得到。
我们和SoulChat 进⾏了对⽐（最后部分），我们的模型在体验和安全上更有优势。
我们只使⽤了2K的数据进⾏了p-tuning 微调，这充分说明了我们构造的数据质量⽐较⾼。
模型权重可以在 HuggingFace 访问，欢迎各位使⽤并提出宝贵的意⻅。
Anima：基于QLoRA的33B中⽂⼤语⾔模型https://github.com/lyogavin/AnimaAI Community从来都是⾮常开放的，AI发展到今天，离不开很多以前的重要开源⼯作，开放共享的Paper，或者的开源数据和代码。
我们相信AI的未来也⼀定是开放的。
希望能为开源社区做⼀些贡献。
为什么33B模型很重要？QLoRA是个Game Changer？之前⼤部分开源可finetune的模型⼤都是⽐较⼩的模型7B或者13B，虽然可以在⼀些简单的chatbot评测集上，通过finetune训练有不错的表现。
但是由于这些模型规模还是有限，LLM核⼼的reasoning的能⼒还是相对⽐较弱。
这就是为什么很多这种⼩规模的模型在实际应⽤的场景表现像是个玩具。
如这个⼯作中的论述：chatbot评测集⽐较简单，真正⽐较考验模型能⼒的复杂逻辑推理及数学问题上⼩模型和⼤模型差距还是很明显的。
因此我们认为QLoRA 的⼯作很重要，重要到可能是个Game Changer。
通过QLoRA的优化⽅法，第⼀次让33B规模的模型可以⽐较⺠主化的，⽐较低成本的finetune训练，并且普及使⽤。
我们认为33B模型既可以发挥⼤规模模型的⽐较强的reasoning能⼒，⼜可以针对私有业务领域数据进⾏灵活的finetune训练提升对于LLM的控制⼒。
BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Modelshttps://github.com/ictnlp/BayLinghttps://arxiv.org/abs/2306.10968BayLing (百聆, bǎi líng) is an instruction-following large language model equipped with advanced language alignment, showing superior capability in English/Chinese generation, instruction following and multi-turn interaction. BayLing can be effortlessly deployed on a consumer-grade GPU with 16GB of memory, and assists users with tasks such as translation, writing, creation, suggestion...BBT-FinCUGE-Applicationshttps://github.com/ssymmetry/BBT-FinCUGE-Applicationshttps://arxiv.org/abs/2302.09432https://bbt.ssymmetry.com/index.html1.⽬前最⼤规模的中⽂⾦融领域开源语料库BBT-FinCorpus。
预训练语料库的规模与多样性对PLM的性能和泛化能⼒具有重要作⽤，所以为了更好的训练PLM，⾸先需要搜集⼤规模多样性的语料库。
然⽽，⽬前中⽂⾦融领域缺乏⼤规模多样性开源语料库，已有的中⽂⾦融领域模型多数基于⼩规模的私有语料库，严重限制了中⽂⾦融PLM的能⼒提升。
为此，我们构建了BBT-FinCorpus，⼀个包含有从四种异质性来源获取的约300GB⽂本的⼤规模多样性语料库。
针对如何确定语料库的覆盖范围和语料来源集合的问题，我们⾸先搜集了中⽂互联⽹上可获取的所有中⽂⾦融NLP任务数据集，并根据其⽂本来源分布来确定所需要爬取的⽂本来源集合。
在确认好需要爬取的⽂本来源集合之后，我们使⽤基于代理的分布式爬⾍技术实现⼤规模爬取⽹⻚上的⽂本。
2.⽬前最⼤规模的中⽂⾦融领域知识增强型预训练语⾔模型BBT-FinT5。
PLM的架构与参数量对其性能有重要影响。
现有的中⽂⾦融领域PLM都基于较为原始的BERT模型架构，参数量也相对较⼩，不能满⾜⽇益丰富的领域NLP需求。
因此，我们基于T5模型架构构建了⼀个拥有⼗亿参数量的⽬前最⼤规模的中⽂⾦融领域预训练语⾔模型BBT-FinT5。
为了在有限的硬件算⼒条件下，尽可能⾼效地利⽤好硬件算⼒，我们使⽤DeepSpeed加速框架对预训练过程进⾏效率优化。
此外，我们还针对T5模型设计了独特的知识增强预训练⽅法，通过实验证明了该⽅法的有效性。
3.⾸个中⽂⾦融领域⾃然语⾔处理评测基准CFLEB。
现有的⾃然语⾔处理评估基准多是通⽤领域的，没有公开可⽤的中⽂⾦融领域评测基准。
这导致中⽂⾦融领域现有的预训练语⾔模型在不同的任务集合上进⾏评测，难以相互⽐较，阻碍了中⽂⾦融领域PLM性能的快速提升。
为此，我们⾸先构建了⾸个中⽂⾦融领域⾃然语⾔处理评测基准CFLEB，包含六种不同的任务，涵盖对PLM理解与⽣成能⼒的评估。
针对评测基准任务的选择及其选择标准问题，我们认为领域评测基准应当着重强调任务的实⽤性，以更好的反映学术界改进PLM对现实世界的帮助。
为此，我们⾸先邀请⾦融领域专家对所有可获取的中⽂⾦融任务进⾏了实⽤性评价，筛选出具有较⾼实⽤性评分的任务。
之后，我们综合任务数据集的开源情况确定了六个任务数据集作为最终的评测基准。
该评测基准的早期版本命名为FinCUGE，包含⼋个任务，该版本⽬前已舍弃。
BELLE: Bloom-Enhanced Large Language model Enginehttps://huggingface.co/BelleGrouphttps://github.com/LianjiaTech/BELLEhttps://zhuanlan.zhihu.com/p/616079388本项⽬⽬标是促进中⽂对话⼤模型开源社区的发展，愿景做能帮到每⼀个⼈的LLM Engine。
现阶段本项⽬基于⼀些开源预训练⼤语⾔模型（如BLOOM），针对中⽂做了优化，模型调优仅使⽤由ChatGPT⽣产的数据（不包含任何其他数据）。
本项⽬基于 Stanford Alpaca ，Stanford Alpaca 的⽬标是构建和开源⼀个基于LLaMA的模型。
 Stanford Alpaca 的种⼦任务都是英语，收集的数据也都是英⽂，因此训练出来的模型未对中⽂优化。
本项⽬⽬标是促进中⽂对话⼤模型开源社区的发展。
本项⽬针对中⽂做了优化，模型调优仅使⽤由ChatGPT⽣产的数据（不包含任何其他数据）。
Bloomhttps://huggingface.co/blog/bloomhttps://huggingface.co/bigscience/bloomBLOOM is an autoregressive Large Language Model (LLM), trained to continue text from a prompt on vast amounts of text data using industrial-scale computational resources. As such, it is able to output coherent text in 46 languages and 13 programming languages that is hardly distinguishable from text written by humans. BLOOM can also be instructed to perform text tasks it hasn't been explicitly trained for, by casting them as text generation tasks.BiLLa: A Bilingual LLaMA with Enhanced Reasoning Abilityhttps://zhuanlan.zhihu.com/p/628688680https://github.com/Neutralzz/BiLLaBiLLa是开源的推理能⼒增强的中英双语LLaMA模型。
模型的主要特性有：较⼤提升LLaMA的中⽂理解能⼒，并尽可能减少对原始LLaMA英⽂能⼒的损伤；训练过程增加较多的任务型数据，利⽤ChatGPT⽣成解析，强化模型理解任务求解逻辑；全量参数更新，追求更好的⽣成效果。
BLOOMChat176Bhttps://mp.weixin.qq.com/s/cY6ORD8CUyXRL0l20EjwqQhttps://sambanova.ai/blog/introducing-bloomchat-176b-the-multilingual-chat-based-llm/https://huggingface.co/spaces/sambanovasystems/BLOOMChathttps://github.com/sambanova/bloomchat开源对话模型⼀直跟闭源模型在多语⾔能⼒上存在差距。
SambaNova 和斯坦福 Together Computer 开源可商⽤的多语⾔聊天模型 BLOOMChat 176B，⽀持中⽂。
BLOOMChat 在SambaNova ⾃研芯⽚ RDU 上完成训练，借助 SambaNova 的独特可重构数据流架构，利⽤ BLOOM开源模型的核⼼能⼒，通过在 OpenChatKit、Dolly 2.0 和 OASST1 的 OIG 上进⾏微调。
在基于六种语⾔的早期双盲测试中，BLOOMChat 在66%的测评数据上产⽣的对话表现优于近期的开源对话模型。
同时在与 GPT4 的基于六种语⾔的⼈⼯测评对⽐中，BLOOMChat 得到 45%对55%的胜率，⼤⼤缩⼩开源和闭源模型的多语⾔对话能⼒差距。
当前 BLOOMChat 开源模型⽂件，⽀持在 huggingface 在线推理试⽤。
ChatLaw 法律⼤模型https://www.chatlaw.cloud/https://github.com/PKU-YuanGroup/ChatLawhttps://arxiv.org/pdf/2306.16092.pdf但愿世间不纷争，何惜法典卷⽣尘ChatGPT浪潮下，⼈⼯智能的不断扩展和发展为LLM的扩散提供了肥沃的⼟壤，⽬前医疗、教育、⾦融领域已逐渐有了各⾃的模型，但法律领域迟迟没有明显进展。
为了促进LLM在法律甚⾄其他垂直应⽤落地的开放研究，本项⽬开源了中⽂法律⼤模型，并针对LLM和知识库的结合问题给出了法律场景下合理的解决⽅案。
ChatLaw法律⼤模型⽬前开源的仅供学术参考的版本底座为姜⼦⽛-13B、Anima-33B，我们使⽤⼤量法律新闻、法律论坛、法条、司法解释、法律咨询、法考题、判决⽂书等原始⽂本来构造对话数据。
基于姜⼦⽛-13B的模型是第⼀版模型，得益于姜⼦⽛的优秀中⽂能⼒和我们对数据清洗、数据增强过程的严格要求，我们在逻辑简单的法律任务上表现优异，但涉及到复杂逻辑的法律推理任务时往往表现不佳。
随后基于Anima-33B，我们增加了训练数据，做成了ChatLaw-33B，发现逻辑推理能⼒⼤幅提升，由此可⻅，⼤参数的中⽂LLM是⾄关重要的。
我们的技术报告在这⾥: arXiv: ChatLaw基于可商⽤的模型训练⽽成的版本会作为我们后续产品内部接⼊的版本，对外不开源，可以在这⾥进⾏开源版本模型的试⽤Chinese-Vicuna-medicalhttps://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-medical.md在cMedQA2上使⽤我们的checkpoint-11600 continue finetune⽬前从2个epoch的Vicuna开始continue finetune，效果⽐3个epoch的在医疗问答数据更具有专业性，同时由于数据集构建的问题，会更加规范，⽐如经常性的加上“到正规医院检查”等等同时验证了指令微调的有效性使⽤单指令continue-finetune能保留原来更多的性能Cornucopia-LLaMA-Fin-Chinesehttps://github.com/jerry1993-tech/Cornucopia-LLaMA-Fin-Chinese聚宝盆(Cornucopia): 基于中⽂⾦融知识的LLaMA微调模型 本项⽬开源了经过中⽂⾦融知识指令精调/指令微调(Instruct-tuning) 的LLaMA-7B模型。
通过中⽂⾦融公开数据+爬取的⾦融数据构建指令数据集，并在此基础上对LLaMA进⾏了指令微调，提⾼了 LLaMA 在⾦融领域的问答效果。
基于相同的数据，后期还会利⽤GPT3.5 API构建⾼质量的数据集，另在中⽂知识图谱-⾦融上进⼀步扩充⾼质量的指令数据集陆续会发布研发的新模型（next-pretrain、multi-task SFT、RLHF Optimize），欢迎⼤家届时使⽤体验。
chatglm-mathshttps://github.com/yongzhuo/chatglm-mathschatglm-6b微调/LORA/PPO/推理, 样本为⾃动⽣成的整数/⼩数加减乘除运算, 可gpu/cpu。
ChatRWKVhttps://github.com/BlinkDL/ChatRWKVChatRWKV is like ChatGPT but powered by my RWKV (100% RNN) language model, which is the only RNN (as of now) that can match transformers in quality and scaling, while being faster and saves VRAM. Training sponsored by Stability EleutherAI :)ChatYuanhttps://github.com/clue-ai/ChatYuanhttps://modelscope.cn/models/ClueAI/ChatYuan-large元语功能型对话⼤模型, 这个模型可以⽤于问答、结合上下⽂做对话、做各种⽣成任务，包括创意性写作，也能回答⼀些像法律、新冠等领域问题。
它基于PromptCLUE-large结合数亿条功能对话多轮对话数据进⼀步训练得到。
PromptCLUE-large在1000亿token中⽂语料上预训练，累计学习1.5万亿中⽂token，并且在数百种任务上进⾏Prompt任务式训练。
针对理解类任务，如分类、情感分析、抽取等，可以⾃定义标签体系；针对多种⽣成任务，可以进⾏采样⾃由⽣成。
ChatGLM-6Bhttps://github.com/THUDM/ChatGLM-6Bhttps://github.com/THUDM/ChatGLM-6B/tree/main/ptuningChatGLM-6B 是⼀个开源的、⽀持中英双语的对话语⾔模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。
结合模型量化技术，⽤户可以在消费级的显卡上进⾏本地部署（INT4 量化级别下最低只需 6GB 显存）。
 ChatGLM-6B 使⽤了和 ChatGPT 相似的技术，针对中⽂问答和对话进⾏了优化。
经过约 1T 标识符的中英双语训练，辅以监督微调、反馈⾃助、⼈类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能⽣成相当符合⼈类偏好的回答。
更多信息请参考我们的博客。
ChatGLM2-6Bhttps://github.com/THUDM/ChatGLM2-6BChatGLM2-6B 是开源中英双语对话模型 ChatGLM-6B 的第⼆代版本，在保留了初代模型对话流畅、部署⻔槛较低等众多优秀特性的基础之上，ChatGLM2-6B 引⼊了如下新特性：更强⼤的性能：基于 ChatGLM 初代模型的开发经验，我们全⾯升级了 ChatGLM2-6B 的基座模型。
ChatGLM2-6B 使⽤了 GLM 的混合⽬标函数，经过了 1.4T 中英标识符的预训练与⼈类偏好对⻬训练，评测结果显示，相⽐于初代模型，ChatGLM2-6B 在 MMLU（+23%）、CEval（+33%）、GSM8K（+571%） 、BBH（+60%）等数据集上的性能取得了⼤幅度的提升，在同尺⼨开源模型中具有较强的竞争⼒。
更⻓的上下⽂：基于 FlashAttention 技术，我们将基座模型的上下⽂⻓度（Context Length）由 ChatGLM-6B 的 2K 扩展到了 32K，并在对话阶段使⽤ 8K 的上下⽂⻓度训练，允许更多轮次的对话。
但当前版本的 ChatGLM2-6B 对单轮超⻓⽂档的理解能⼒有限，我们会在后续迭代升级中着重进⾏优化。
更⾼效的推理：基于 Multi-Query Attention 技术，ChatGLM2-6B 有更⾼效的推理速度和更低的显存占⽤：在官⽅的模型实现下，推理速度相⽐初代提升了 42%，INT4 量化下，6G 显存⽀持的对话⻓度由 1K 提升到了 8K。
更开放的协议：ChatGLM2-6B 权重对学术研究完全开放，在获得官⽅的书⾯许可后，亦允许商业使⽤。
如果您发现我们的开源模型对您的业务有⽤，我们欢迎您对下⼀代模型 ChatGLM3 研发的捐赠。
Chinese-Transformer-XLhttps://github.com/THUDM/Chinese-Transformer-XL本项⽬提供了智源研究院"⽂汇" 预训练模型Chinese-Transformer-XL的预训练和⽂本⽣成代码。
ChatMed-TCM & ChatMed-Consulthttps://github.com/michael-wzhu/ChatMedChatMed-Consult : 基于中⽂医疗在线问诊数据集ChatMed_Consult_Dataset的50w+在线问诊+ChatGPT回复作为训练集。
模型主⼲为LlaMA-7b,融合了Chinese-LlaMA-Alpaca的LoRA权重与中⽂扩展词表，然后再进⾏基于LoRA的参数⾼效微调。
我们将全部代码都进⾏了公开。
我们也将部署⼀个在线Gradio demo, 敬请关注。
ChatMed-TCM : ⼤模型赋能中医药传承。
这⼀模型的训练数据为中医药指令数据集ChatMed_TCM_Dataset。
以我们开源的中医药知识图谱为基础，采⽤以实体为中⼼的⾃指令⽅法(entity-centric self-instruct)，调⽤ChatGPT得到2.6w+的围绕中医药的指令数据。
ChatMed-TCM模型也是以LlaMA为底座，采⽤LoRA微调得到。
ChatGLM-Medhttps://github.com/SCIR-HI/Med-ChatGLM基于中⽂医学知识的ChatGLM模型微调，本项⽬开源了经过中⽂医学指令精调/指令微调(Instruct-tuning) 的ChatGLM-6B模型。
我们通过医学知识图谱和GPT3.5 API构建了中⽂医学指令数据集，并在此基础上对ChatGLM-6B进⾏了指令微调，提⾼了ChatGLM在医疗领域的问答效果。
CPM-Beehttps://mp.weixin.qq.com/s/UCW1BT60Lr9x24Rj0cLuxwhttps://huggingface.co/openbmb/cpm-bee-10bhttps://github.com/OpenBMB/CPM-BeeCPM-Bee 是⼀个 完全开源、允许商⽤ 的百亿参数中英⽂基座模型。
它采⽤ Transformer ⾃回归架构（auto-regressive），使⽤万亿级⾼质量语料进⾏预训练，拥有强⼤的基础能⼒。
CPM-Bee 的特点可以总结如下：开源可商⽤：OpenBMB 始终秉承“让⼤模型⻜⼊千家万户”的开源精神，CPM-Bee 基座模型将完全开源并且可商⽤，以推动⼤模型领域的发展。
如需将模型⽤于商业⽤途，只需企业实名邮件申请并获得官⽅授权证书，即可商⽤使⽤。
中英双语性能优异：CPM-Bee 基座模型在预训练语料上进⾏了严格的筛选和配⽐，同时在中英双语上具有亮眼表现，具体可参⻅评测任务和结果。
超⼤规模⾼质量语料：CPM-Bee基座模型在万亿级语料上进⾏训练，是开源社区内经过语料最多的模型之⼀。
同时，我们对预训练语料进⾏了严格的筛选、清洗和后处理以确保质量。
OpenBMB⼤模型系统⽣态⽀持：OpenBMB ⼤模型系统在⾼性能预训练、适配、压缩、部署、⼯具开发了⼀系列⼯具，CPM-Bee 基座模型将配套所有的⼯具脚本，⾼效⽀持开发者进⾏进阶使⽤。
强⼤的对话和⼯具使⽤能⼒：结合OpenBMB 在指令微调和⼯具学习的探索，我们在 CPM-Bee 基座模型的基础上进⾏微调，训练出了具有强⼤对话和⼯具使⽤能⼒的实例模型，现已开放定向邀请内测，未来会逐步向公众开放。
* 【Data-Copilot】https://github.com/zwq2018/Data-Copilothttps://arxiv.org/abs/2306.07209https://huggingface.co/spaces/zwq2018/Data-CopilotData-Copilot 是⼀个基于 LLM 的系统，⽤于处理与数据相关的任务，连接了数⼗亿条数据和多样化的⽤户需求。
它独⽴设计接⼝⼯具，以⾼效地管理、调⽤、处理和可视化数据。
在接收到复杂请求时，Data-Copilot 会⾃主调⽤这些⾃设计的接⼝，构建⼀个⼯作流程来满⾜⽤户的意图。
在没有⼈类协助的情况下，它能够熟练地将来⾃不同来源、不同格式的原始数据转化为⼈性化的输出，如图形、表格和⽂本。
DoctorGLM⏳!https://github.com/xionghonglin/DoctorGLMDoctorGLM，基于 ChatGLM-6B的中⽂问诊模型。
EduChathttps://github.com/icalk-nlp/EduChat教育是影响⼈的身⼼发展的社会实践活动，旨在把⼈所固有的或潜在的素质⾃内⽽外激发出来。
因此，必须贯彻“以⼈为本”的教育理念，重点关注⼈的个性化、引导式、身⼼全⾯发展。
为了更好地助⼒”以⼈为本“的教育，华东师范⼤学计算机科学与技术学院的EduNLP团队探索了针对教育垂直领域的对话⼤模型EduChat相关项⽬研发。
该项⽬主要研究以预训练⼤模型为基底的教育对话⼤模型相关技术，融合多样化的教育垂直领域数据，辅以指令微调、价值观对⻬等⽅法，提供教育场景下⾃动出题、作业批改、情感⽀持、课程辅导、⾼考咨询等丰富功能，服务于⼴⼤⽼师、学⽣和家⻓群体，助⼒实现因材施教、公平公正、富有温度的智能教育。
EVA: ⼤规模中⽂开放域对话系统https://github.com/thu-coai/EVAEVA 是⽬前最⼤的开源中⽂预训练对话模型，拥有28亿参数，主要擅⻓开放域闲聊，⽬前有 1.0 和 2.0 两个版本。
其中，1.0版本在 WudaoCorpus-Dialog 上训练⽽成，2.0 版本在从 WudaoCorpus-Dialog 中清洗出的更⾼质量的对话数据上训练⽽成，模型性能也明显好于 EVA1.0。
GPT2 for Multiple Languagehttps://github.com/imcaspar/gpt2-ml简化整理 GPT2 训练代码（based on Grover, supporting TPUs）移植 bert tokenizer，添加多语⾔⽀持15亿参数 GPT2 中⽂预训练模型( 15G 语料，训练 10w 步 )开箱即⽤的模型⽣成效果 demo #15亿参数 GPT2 中⽂预训练模型( 30G 语料，训练 22w 步 )InternLM 书⽣・浦语https://github.com/InternLMhttps://mp.weixin.qq.com/s/oTXnvWZJVdoOpFLHngbTYQhttps://intern-ai.org.cn/homeInternLM has open-sourced a 7 billion parameter base model and a chat model tailored for practical scenarios. The model has the following characteristics:It leverages trillions of high-quality tokens for training to establish a powerful knowledge base. It supports an 8k context window length, enabling longer input sequences and stronger reasoning capabilities.It provides a versatile toolset for users to flexibly build their own workflows. Additionally, a lightweight training framework is offered to support model pre-training without the need for extensive dependencies. With a single codebase, it supports pre-training on large-scale clusters with thousands of GPUs, and fine-tuning on a single GPU while achieving remarkable performance optimizations. InternLM achieves nearly 90% acceleration efficiency during training on 1024 GPUs.LaWGPThttps://github.com/pengxiao-song/LaWGPTLaWGPT 是⼀系列基于中⽂法律知识的开源⼤语⾔模型。
该系列模型在通⽤中⽂基座模型（如 Chinese-LLaMA、ChatGLM 等）的基础上扩充法律领域专有词表、⼤规模中⽂法律语料预训练，增强了⼤模型在法律领域的基础语义理解能⼒。
在此基础上，构造法律领域对话问答数据集、中国司法考试数据集进⾏指令精调，提升了模型对法律内容的理解和执⾏能⼒。
Lawyer LLaMAhttps://github.com/AndrewZhe/lawyer-llamaLawyer LLaMA ⾸先在⼤规模法律语料上进⾏了continual pretraining，让它系统的学习中国的法律知识体系。
 在此基础上，我们借助ChatGPT收集了⼀批对中国国家统⼀法律职业资格考试客观题（以下简称法考）的分析和对法律咨询的回答，利⽤收集到的数据对模型进⾏指令微调，让模型习得将法律知识应⽤到具体场景中的能⼒。
我们的模型能够：掌握中国法律知识： 能够正确的理解⺠法、刑法、⾏政法、诉讼法等常⻅领域的法律概念。
例如，掌握了刑法中的犯罪构成理论，能够从刑事案件的事实描述中识别犯罪主体、犯罪客体、犯罪⾏为、主观⼼理状态等犯罪构成要件。
模型利⽤学到的法律概念与理论，能够较好回答法考中的⼤部分题⽬。
应⽤于中国法律实务：能够以通俗易懂的语⾔解释法律概念，并且进⾏基础的法律咨询，涵盖婚姻、借贷、海商、刑事等法律领域。
为了给中⽂法律⼤模型的开放研究添砖加瓦，本项⽬将开源⼀系列法律领域的指令微调数据和基于LLaMA训练的中⽂法律⼤模型的参数。
LexiLawhttps://github.com/CSHaitao/LexiLawLexiLaw 是⼀个经过微调的中⽂法律⼤模型，它基于 ChatGLM-6B 架构，通过在法律领域的数据集上进⾏微调，使其在提供法律咨询和⽀持⽅⾯具备更⾼的性能和专业性。
该模型旨在为法律从业者、学⽣和普通⽤户提供准确、可靠的法律咨询服务。
⽆论您是需要针对具体法律问题的咨询，还是对法律条款、案例解析、法规解读等⽅⾯的查询，LexiLaw 都能够为您提供有益的建议和指导。
同时，我们将分享在⼤模型基础上微调的经验和最佳实践，以帮助社区开发更多优秀的中⽂法律⼤模型，推动中⽂法律智能化的发展。
LawGPT_zh 中⽂法律⼤模型（獬⾘）https://mp.weixin.qq.com/s/Pk4NdFQq5G6iZ3QmcyyFUghttps://github.com/LiuHC0428/LAW-GPT我们的愿景是为让所有⼈在遇到法律问题时能第⼀时间获得专业可靠的回答。
因为专业的律师服务只有真正触⼿可及，才会让⼈们习惯运⽤，⼀如⼆⼗年前的搜索引擎，⼗年前的快递业务。
我们希望让法律⾛进⽇常⽣活，为构建法治社会贡献我们的⼒量。
项⽬海报由Midjourney⽣成。
本项⽬开源的中⽂法律通⽤模型由ChatGLM-6B LoRA 16-bit指令微调得到。
数据集包括现有的法律问答数据集和基于法条和真实案例指导的self-Instruct构建的⾼质量法律⽂本问答，提⾼了通⽤语⾔⼤模型在法律领域的表现，提⾼了模型回答的可靠性和专业程度。
Linly伶荔说https://github.com/CVI-SZU/Linlyhttps://mp.weixin.qq.com/s/zSxsArP1pxYNubNDZua7iA“伶荔说”模型具有以下优势：1. 在32*A100 GPU上训练了不同量级和功能的中⽂模型，对模型充分训练并提供强⼤的baseline。
据我们所知33B的Linly-Chinese-LLAMA是⽬前最⼤的中⽂LLaMA模型。
2. 公开所有训练数据、代码、参数细节以及实验结果，确保项⽬的可复现性，⽤户可以选择合适的资源直接⽤于⾃⼰的流程中。
3. 项⽬具有⾼兼容性和易⽤性，提供可⽤于CUDA和CPU的量化推理框架，并⽀持Huggingface格式。
⽬前公开可⽤的模型有：Linly-Chinese-LLaMA：中⽂基础模型，基于LLaMA在⾼质量中⽂语料上增量训练强化中⽂语⾔能⼒，现已开放 7B、13B 和 33B 量级，65B正在训练中。
Linly-ChatFlow：中⽂对话模型，在400万指令数据集合上对中⽂基础模型指令精调，现已开放7B、13B对话模型。
Linly-ChatFlow-int4 ：ChatFlow 4-bit量化版本，⽤于在CPU上部署模型推理。
进⾏中的项⽬： Linly-Chinese-BLOOM：基于BLOOM中⽂增量训练的中⽂基础模型，包含7B和175B模型量级，可⽤于商业场景。
Linly伶荔说-Chinese-Falconhttps://mp.weixin.qq.com/s/AuAG3tw4JI8lHyLkSdM18ghttps://github.com/CVI-SZU/Linly近期，阿联酋阿布扎⽐的技术创新研究所（TII）开源了 Falcon 系列模型，使⽤经过筛选的 1 万亿 tokens 进⾏预训练，并以 Apache 2.0 协议开源，可能是⽬前效果最好且许可协议最宽松（允许商⽤）的开源模型。
然⽽，Falcon 模型在使⽤上⾯临和 LLaMA 模型类似的问题：由于模型主要在英⽂数据集上训练，因此它理解和⽣成中⽂的能⼒偏弱。
此外，Falcon 在构建词表时没有加⼊中⽂字/词，中⽂字会被拆分成多个 token 的组合，这导致中⽂⽂本会被拆分成更⻓的 tokens 序列，降低了编码和⽣成效率。
针对以上问题，“伶荔（Linly）”项⽬团队以 Falcon 模型为底座扩充中⽂词表，利⽤中⽂和中英平⾏增量预训练将模型的语⾔能⼒迁移学习到中⽂，实现 Chinese-Falcon。
本⽂从模型结构上分析 Falcon、LLaMA 与传统 GPT 的异同，代码实现细节。
并介绍我们的中⽂ Falcon 训练⽅案，包括中⽂字词扩充、数据集构建和训练参数等。
MeChat (Mental Health Support Chatbot)https://github.com/qiuhuachuan/smilehttps://huggingface.co/qiuhuachuan/MeChathttps://mechat.fly.dev/我们的愿景是为让所有⼈在遇到⼼理健康问题时能够获得及时、有效的倾听和⽀持。
我们相信，⼼理健康是每个⼈的权利，⽽不是奢侈品。
我们的使命是为⼈们提供平等、全⾯、易于访问的⼼理健康服务，⽆论他们身在何处、⾯临何种挑战。
我们的愿景还包括推动社会对⼼理健康问题的认识和理解，打破⼼理健康问题带来的污名和歧视，为创建⼀个更加健康、包容和平等的社会做出贡献。
项⽬海报取⾃ flaticon 。
MedicalGPThttps://github.com/shibing624/MedicalGPTMedicalGPT 训练医疗⼤模型，实现包括⼆次预训练、有监督微调、奖励建模、强化学习训练。
基于ChatGPT Training Pipeline，本项⽬实现了领域模型--医疗模型的四阶段训练：第⼀阶段：PT(Continue PreTraining)增量预训练，在海量领域⽂档数据上⼆次预训练GPT模型，以注⼊领域知识第⼆阶段：SFT(Supervised Fine-tuning)有监督微调，构造指令微调数据集，在预训练模型基础上做指令精调，以对⻬指令意图第三阶段：RM(Reward Model)奖励模型建模，构造⼈类偏好排序数据集，训练奖励模型，⽤来对⻬⼈类偏好，主要是"HHH"原则，具体是"helpful, honest, harmless"第四阶段：RL(Reinforcement Learning)基于⼈类反馈的强化学习(RLHF)，⽤奖励模型来训练SFT模型，⽣成模型使⽤奖励或惩罚来更新其策略，以便⽣成更⾼质量、更符合⼈类偏好的⽂本MedicalGPT-zhgithub.com/MediaBrain-SJTU/MedicalGPT-zh该开源了基于ChatGLM-6B LoRA 16-bit指令微调的中⽂医疗通⽤模型。
基于共计28科室的中⽂医疗共识与临床指南⽂本，我们⽣成医疗知识覆盖⾯更全，回答内容更加精准的⾼质量指令数据集。
OpenKG-KnowLLMhttps://github.com/zjunlp/KnowLLMKnowledgable Large Language Model Series.With the rapid development of deep learning technology, large language models such as ChatGPT have achieved significant success in thefield of natural language processing. However, these large models still face some challenges and issues in learning and understanding knowledge, including the difficulty of knowledge updating, and issues with potential errors and biases within the model, known as knowledge fallacies. The Deep Model series aims to release a series of open-source large models to mitigate these knowledge fallacy issues. The firstphase of this project released a knowledge extraction large model based on LLaMA, named Zhishi. To provide Chinese capabilities withoutdisrupting the original model's distribution, we firstly (1) use Chinese corpora for the full-scale pre-training of LLaMA (13B), in order to improve the model's understanding of Chinese and knowledge reserve as much as possible while retaining its original English and code capabilities; Then (2) we fine-tune the model from the first step using an instruction dataset, to enhance the language model's understanding ofhuman extraction instructions.OpenMEDLab 浦医https://github.com/OpenMEDLabhttps://github.com/openmedlab/PULSEhttps://stcsm.sh.gov.cn/xwzx/kjzl/20230630/c783c30d8e62494e83073535f841675f.htmlOpenMEDLab is an open-source platform to share medical foundation models in multi-modalities, e.g., medical imaging, medical NLP, bioinformatics, protein, etc. It targets promoting novel approaches to long-tail problems in medicine, and meanwhile, it seeks solutions to achieve lower cost, higher efficiency, and better generalizability in training medical AI models. The new learning paradigm of adapting foundation models to downstream applications makes it possible to develop innovative solutions for cross-domain and cross-modality diagnostic tasks efficiently. OpenMEDLab is distinguished by several features:World's first open-source platform for medical foundation models.10+ medical data modalities targeting a variety of clinical and research problems.Pioneering works of the new learning paradigm using foundation models, including pre-trained models, code, and data.Releasing multiple sets of medical data for pre-training and downstream applications.Collaboration with top medical institutes and facilities.PromptCLUEhttps://github.com/clue-ai/PromptCLUEPromptCLUE：⼤规模多任务Prompt预训练中⽂开源模型。
中⽂上的三⼤统⼀：统⼀模型框架，统⼀任务形式，统⼀应⽤⽅式。
⽀持⼏⼗个不同类型的任务，具有较好的零样本学习能⼒和少样本学习能⼒。
针对理解类任务，如分类、情感分析、抽取等，可以⾃定义标签体系；针对⽣成任务，可以进⾏采样⾃由⽣成。
千亿中⽂token上⼤规模预训练，累计学习1.5万亿中⽂token，亿级中⽂任务数据上完成训练，训练任务超过150+。
⽐base版平均任务提升7个点+；具有更好的理解、⽣成和抽取能⼒，并且⽀持⽂本改写、纠错、知识图谱问答。
SkyText-Chinese-GPT3https://github.com/SkyWorkAIGC/SkyText-Chinese-GPT3SkyText是由奇点智源发布的中⽂GPT3预训练⼤模型，可以进⾏聊天、问答、中英互译等不同的任务。
 应⽤这个模型，除了可以实现基本的聊天、对话、你问我答外，还能⽀持中英⽂互译、内容续写、对对联、写古诗、⽣成菜谱、第三⼈称转述、创建采访问题等多种功能。
ShenNong-TCM-LLMhttps://github.com/michael-wzhu/ShenNong-TCM-LLM为推动LLM在中医药领域的发展和落地，提升LLM的在中医药⽅⾯的知识与回答医学咨询的能⼒，同时推动⼤模型赋能中医药传承，我们现推出ShenNong中医药⼤规模语⾔模型:ShenNong-TCM :这⼀模型的训练数据为中医药指令数据集ShenNong_TCM_Dataset。
ChatMed_TCM_Dataset以我们开源的中医药知识图谱为基础；采⽤以实体为中⼼的⾃指令⽅法entity-centric self-instruct，调⽤ChatGPT得到11w+的围绕中医药的指令数据；ShenNong-TCM模型也是以LlaMA为底座，采⽤LoRA (rank=16)微调得到。
微调代码与ChatMed代码库相同TableGPThttps://github.com/ZJU-M3/TableGPT-techreportTableGPT is a specifically designed for table analysis. By unifying tables, natural language, and commands into one model, TableGPT comprehends tabular data, understands user intent through natural language, dissects the desired actions, and executes external commands onthe table. It subsequently returns the processed results in both tabular and textual explanations to the user. This novel approach simplifiesthe way users engage with table data, bringing an intuitive feel to data analysis.TechGPThttps://mp.weixin.qq.com/s/nF1He7jhAHfh7PzhjqHoZghttps://huggingface.co/neukg/TechGPT-7Bhttps://github.com/neukg/TechGPT2023年6⽉26⽇，“东北⼤学知识图谱研究组”正式发布⼤语⾔模型TechGPT。
!TechGPT的名字主要来源于⼩组在2018年推出的TechKG⼤规模中⽂学术多领域的知识库。
与当前其他各类⼤模型相⽐，TechGPT主要强化了以“知识图谱构建”为核⼼的关系三元组抽取等各类信息抽取任务、以“逻辑推理”为核⼼的机器阅读理解等各类智能问答任务、以“⽂本理解”为核⼼的关键词⽣成等各类序列⽣成任务。
在这三⼤⾃然语⾔处理核⼼能⼒之内，TechGPT还具备了对计算机科学、材料、机械、冶⾦、⾦融和航空航天等⼗余种垂直专业领域⾃然语⾔⽂本的处理能⼒。
TigerBothttps://github.com/TigerResearch/TigerBotTigerBot 是⼀个多语⾔多任务的⼤规模语⾔模型(LLM)。
根据 OpenAI InstructGPT 论⽂在公开 NLP 数据集上的⾃动评测，TigerBot-7B 达到OpenAI 同样⼤⼩模型的综合表现的 96%，并且这只是我们的 MVP，在此我们将如下探索成果开源：模型：TigerBot-7B, TigerBot-7B-base，TigerBot-180B (research version)，代码：基本训练和推理代码，包括双卡推理 180B 模型的量化和推理代码，数据：预训练 100G，从 2TB 过滤后的数据中经过去噪去重清洗⽽得；监督微调 1G 或 100 万条数据，按⽐例涵盖⽤户指令常⻅的 10 ⼤类 120 ⼩类任务，API: chat, plugin, finetune, 让⽤户能在半⼩时内⽆代码的训练和使⽤专属于⾃⼰的⼤模型和数据，领域数据：涵盖⾦融，法律，百科，⼴邀⼤模型应⽤开发者，⼀起打造中国的世界级的应⽤。
我们在 BLOOM 基础上，在模型架构和算法上做了如下优化：指令完成监督微调的创新算法以获得更好的可学习型(learnability)，运⽤ ensemble 和 probabilistic modeling 的⽅法实现更可控的事实性(factuality)和创造性(generativeness)，在并⾏训练上，我们突破了 deep-speed 等主流框架中若⼲内存和通信问题，使得在千卡环境下数⽉⽆间断，对中⽂语⾔的更不规则的分布，从 tokenizer 到训练算法上做了更适合的算法优化。
YuLan-Chathttps://github.com/RUC-GSAI/YuLan-Chathttps://mp.weixin.qq.com/s/nPS4N3stAAG_51fnZANbMA中国⼈⺠⼤学⾼瓴⼈⼯智能学院相关研究团队（由多位学院⽼师联合指导）展开了⼀系列关于指令微调技术的研究，并发布了学院初版⼤语⾔对话模型⸺YuLan-Chat，旨在探索和提升⼤语⾔模型的中英⽂双语对话能⼒。
我们分别开源了13B和65B的YuLan-Chat模型⽂件及相关代码，并采⽤量化技术使其分别可以在单张RTX3090-24G和A800-80G显卡上部署。
YuLan-Chat模型基于LLaMA底座模型，采⽤精⼼优化的⾼质量中英⽂混合指令进⾏微调，其中YuLan-Chat-65B模型⽬前能够在中英⽂相关评测数据集上显著超越已有开源模型效果。
后续我们会继续优化指令微调⽅法与底座模型，持续更新YuLan-Chat模型。
Ziya-LLaMAhttps://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1https://github.com/IDEA-CCNL/Fengshenbang-LMhttps://mp.weixin.qq.com/s/IeXgq8blGoeVbpIlAUCAjA姜⼦⽛通⽤⼤模型V1是基于LLaMa的130亿参数的⼤规模预训练模型，具备翻译，编程，⽂本分类，信息抽取，摘要，⽂案⽣成，常识问答和数学计算等能⼒。
⽬前姜⼦⽛通⽤⼤模型已完成⼤规模预训练、多任务有监督微调和⼈类反馈学习三阶段的训练过程。
The Ziya-LLaMA-13B-v1 is a large-scale pre-trained model based on LLaMA with 13 billion parameters. It has the ability to perform tasks such as translation, programming, text classification, information extraction, summarization, copywriting, common sense Q&A, and mathematical calculation. The Ziya-LLaMA-13B-v1 has undergone three stages of training: large-scale continual pre-training (PT), multi-task supervised fine-tuning (SFT), and human feedback learning (RM, PPO).2 训练/推理⾼效对⻬算法RAFT「⽊筏」https://github.com/OptimalScale/LMFlowhttps://arxiv.org/abs/2304.06767https://optimalscale.github.io/LMFlow/examples/raft.htmlAn extensible, convenient, and efficient toolbox for finetuning large machine learning models, designed to be user-friendly, speedy and reliable, and accessible to the entire community.Alpaca-LoRAhttps://github.com/tloen/alpaca-loraLow-Rank LLaMA Instruct-TuningThis repository contains code for reproducing the Stanford Alpaca results using low-rank adaptation (LoRA). We provide an Instruct modelof similar quality to text-davinci-003 that can run on a Raspberry Pi (for research), and the code can be easily extended to the 13b, 30b, and 65b models.In addition to the training code, which runs within five hours on a single RTX 4090, we publish a script for downloading and inference on the foundation model and LoRA, as well as the resulting LoRA weights themselves. To fine-tune cheaply and efficiently, we use Hugging Face's PEFT as well as Tim Dettmers' bitsandbytes.Without hyperparameter tuning or validation-based checkpointing, the LoRA model produces outputs comparable to the Stanford Alpacamodel. (Please see the outputs included below.) Further tuning might be able to achieve better performance; I invite interested users to give it a try and report their results.AlpacaFarmhttps://mp.weixin.qq.com/s/CIF2F5Vx_RSN1-LwU_ppOQhttps://tatsu-lab.github.io/alpaca_farm_paper.pdfhttps://github.com/tatsu-lab/alpaca_farm主流的⼤型语⾔模型训练都离不开RLHF(⼈⼯反馈强化学习)，其主要思想是使⽤⼈类专家提供的反馈示例来指导模型的学习过程，它可以加速强化学习过程，提⾼⼤模型的性能，但「⽬前RLHF这个过程既复杂⼜昂贵」。
针对RLHF这个问题，学术界⽬前主要有两种解决⽅法：「1）避开RLHF」，⽐如Meta最近研究的“Meta最新模型：LIMA-65B，没有RLHF，模型效果远胜Alpaca！！”，验证了精⼼制作的少量标注数据同样能达到不错的效果。
2）「简化RLHF」，就是今天给⼤家分享的这篇⽂章：斯坦福发布了⼀个名为AlpacaFarm（⽺驼农场）的模拟器，旨在降低训练语⾔模型的成本，且⽐⼈⼯成本低45倍，并表现出与⼈类反馈的⾼度⼀致性，同时也为RLHF的研究开辟了新的道路。
ColossalAIhttps://github.com/hpcaitech/ColossalAIColossal-AI: Making large AI models cheaper, faster and more accessibleColossal-AI provides a collection of parallel components for you. We aim to support you to write your distributed deep learning models justlike how you write your model on your laptop. We provide user-friendly tools to kickstart distributed training and inference in a few lines.ChatLLaMAhttps://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllamaChatLLaMA has been designed to help developers with various use cases, all related to RLHF training and optimized inference.ChatLLaMA is a library that allows you to create hyper-personalized ChatGPT-like assistants using your own data and the least amount of compute possible. Instead of depending on one large assistant that “rules us all”, we envision a future where each of us can create our ownpersonalized version of ChatGPT-like assistants. Imagine a future where many ChatLLaMAs at the "edge" will support a variety of human'sneeds. But creating a personalized assistant at the "edge" requires huge optimization efforts on many fronts: dataset creation, efficient training with RLHF, and inference optimization.Chinese-Guanacohttps://github.com/jianzhnie/Chinese-GuanacoThis is the repo for the Chinese-Guanaco project, which aims to build and share instruction-following Chinese LLaMA/Pythia/GLM model tuning methods which can be trained on a single Nvidia RTX-2080TI, multi-round chatbot which can be trained on a single Nvidia RTX-3090with the context len 2048.Chinese-Guanaco uses bitsandbytes for quantization and is integrated with Huggingface's PEFT and transformers libraries.#DPO (Direct Preference Optimization)https://arxiv.org/abs/2305.18290https://zhuanlan.zhihu.com/p/641045324https://huggingface.co/lyogavin/Anima33B-DPO-Belle-1k-mergedhttps://github.com/lyogavin/Anima/tree/main/rlhfDPO的核⼼原理是：PPO训练难度核⼼是因为需要通过reward model来表达偏好，进⾏强化学习。
为了不再依赖于reward model进⾏强化学习，他进⾏了⼀系列的数学变换，直接推导出了基于Policy Language Model的标注偏好的概率表达形式，从⽽可以直接求解⼀个Language Model的最⼤似然估计。
不再需要复杂繁琐的reward model和强化学习。
While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise controlof their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often withreinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper, we leverage a mapping between reward functions and optimalpolicies to show that this constrained reward maximization problem can be optimized exactly with a single stage of policy training, essentially solving a classification problem on the human preference data. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant and computationally lightweight, eliminating the need for fitting a reward model, sampling from the LM during fine-tuning, or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds RLHF's ability to control sentiment of generations and improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.DialogADV：Evaluate What You Can't Evaluate: Unassessable Generated Responses Qualityhttps://github.com/misonsky/DialogADVhttps://mp.weixin.qq.com/s/Ga0a6a1L6CmCXgk6WDz0Xghttps://arxiv.org/abs/2305.14658我们构建了两个具有挑战的元验证对话数据集，通过实验分析表明⼤型语⾔模型作为评估器评估对话⽂本⽣成质量仍然存在很多问题：1）LLMs⽆法识别与事实不⼀致的、虚构的回复，对不合理的回复仍然给出较⾼的评价；2） LLMs⾃身的知识有限，对于依赖知识的样例⼤语⾔模型⽆法依靠⾃身的知识给出合理的判断；3）LLMs利⽤外部知识的能⼒有待提⾼。
在给定外部知识的情况下，LLMs仍然会对不合理的回复给出较⾼的评价。
DeepSpeed-Chathttps://mp.weixin.qq.com/s/t3HA4Hu61LLDC3h2Njmo_Qhttps://github.com/microsoft/DeepSpeed微软宣布开源 DeepSpeed-Chat，帮助⽤户轻松训练类 ChatGPT 等⼤语⾔模型。
据悉，Deep Speed Chat 是基于微软 Deep Speed 深度学习优化库开发⽽成，具备训练、强化推理等功能，还使⽤了 RLHF（基于⼈类反馈的强化学习）技术，可将训练速度提升 15 倍以上，⽽成本却⼤⼤降低。
FlexGenhttps://github.com/FMInference/FlexGenFlexGen is a high-throughput generation engine for running large language models with limited GPU memory. FlexGen allows high-throughput generation by IO-efficient offloading, compression, and large effective batch sizes.Limitation. As an offloading-based system running on weak GPUs, FlexGen also has its limitations. FlexGen can be significantly slower thanthe case when you have enough powerful GPUs to hold the whole model, especially for small-batch cases. FlexGen is mostly optimized forthroughput-oriented batch processing settings (e.g., classifying or extracting information from many documents in batches), on single GPUs.FlagAI and FlagDatahttps://github.com/FlagAI-Open/FlagAIFlagAI (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model. Our goal is to support training, fine-tuning, and deployment of large-scale models on various downstream tasks with multi-modality.https://github.com/FlagOpen/FlagDataFlagData, a data processing toolkit that is easy to use and expand. FlagData integrates the tools and algorithms of multi-step data processing, including cleaning, condensation, annotation and analysis, providing powerful data processing support for model training and deployment in multiple fields, including natural language processing and computer vision.Guanaco & QloRAhttps://mp.weixin.qq.com/s/SGJQHsEJTNB6hiVqdc87sghttps://arxiv.org/abs/2305.14314https://github.com/artidoro/qlorahttps://huggingface.co/blog/hf-bitsandbytes-integrationIntegration: https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf?usp=sharingTraining: https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharingWe present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters (LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuningon a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4),a new data type that is information theoretically optimal for normally distributed weights (b) Double Quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) Paged Optimizers to manage memory spikes. We use QLoRA to finetunemore than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. We release all of our models and code, including CUDA kernels for 4-bit training.GPT4Allhttps://github.com/nomic-ai/gpt4allDemo, data and code to train an assistant-style large language model with ~800k GPT-3.5-Turbo Generations based on LLaMaHugNLPhttps://mp.weixin.qq.com/s/IpgOQJ8vrIvnjdrmGCT2FAhttps://github.com/HugAILab/HugNLPhttps://arxiv.org/abs/2302.14286华师⼤HugAILab团队研发了HugNLP框架，这是⼀个⾯向研究者和开发者的全⾯统⼀的NLP训练框架，可⽀持包括⽂本分类、⽂本匹配、问答、信息抽取、⽂本⽣成、⼩样本学习等多种NLP任务模型搭建和训练。
HugNLP还集成了⼤量最新的Prompt技术，例如Prompt-Tuning、In-Context Learning、Instruction-tuning，未来还将引⼊Chain-of-thoughtHugAILab团队还研发了⼀系列的应⽤，例如CLUE&GLUE刷榜⼯具，可⽀持ChatGPT类模型训练和部署产品HugChat，以及统⼀信息抽取产品HugIE等。
HugNLP是⼀个分层式框架，遵循“⾼内聚低耦合”的开发模式，其核⼼包括模型层（Models）、处理器层（Processors）、评估器层（Evaluators）和应⽤层（Applications）四部分。
INSTRUCTEVALhttps://mp.weixin.qq.com/s/E6hq0AUy_hItA5HGo2tCAQhttps://github.com/declare-lab/instruct-evalhttps://arxiv.org/abs/2306.04757本⽂引⼊了⼀个名为INSTRUCTEVAL的新型评估套件。
该套件专⽤于对指令调优⼤型语⾔模型的全⾯评估，相⽐之前对LLMs的评估⽅法，该评估策略不仅详细评估了模型解决问题的能⼒、⽂字写作能⼒，⽽且还严格评估了模型与⼈类价值的对⻬能⼒。
LOw-Memory Optimization (LOMO)https://arxiv.org/abs/2306.09782https://github.com/OpenLMLab/LOMOLarge Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but demand massive GPU resources for training. Lowering the threshold for LLMs training would encourage greater participation from researchers, benefiting both academia and society. While existing approaches have focused on parameter-efficient fine-tuning, which tunes or adds a small number of parameters, few have addressed the challenge of tuning the full parameters of LLMs with limited resources. In this work, we propose a new optimizer, LOw-MemoryOptimization (LOMO), which fuses the gradient computation and the parameter update in one step to reduce memory usage. By integrating LOMO with existing memory saving techniques, we reduce memory usage to 10.8% compared to the standard approach (DeepSpeed solution). Consequently, our approach enables the full parameter fine-tuning of a 65B model on a single machine with 8 RTX 3090, each with24GB memory.llama.cpphttps://github.com/ggerganov/llama.cppInference of LLaMA model in pure C/C++The main goal is to run the model using 4-bit quantization on a MacBookPlain C/C++ implementation without dependenciesApple silicon first-class citizen - optimized via ARM NEONAVX2 support for x86 architecturesMixed F16 / F32 precision4-bit quantization supportRuns on the CPUMeZO: Fine-Tuning Language Models with Just Forward Passeshttps://github.com/princeton-nlp/MeZOhttps://arxiv.org/abs/2305.17333https://mp.weixin.qq.com/s/3RLCVQg2QJGSiDUtx9DgPgThis is the implementation for the paper Fine-Tuning Language Models with Just Forward Passes. In this paper we propose a memory-efficient zeroth-order optimizer (MeZO), adapting the classical zeroth-order SGD method to operate in-place, thereby fine-tuning language models (LMs) with the same memory footprint as inference.With a single A100 80GB GPU, MeZO can train a 30-billion parameter OPT model, whereas fine-tuning with Adam can train only a 2.7B LM.MeZO demonstrates comparable performance to fine-tuning with backpropagation across multiple tasks, with up to 12× memory reduction. MeZO is also compatible with both full-parameter and parameter-efficient tuning techniques such as LoRA and prefix tuning. We also show that MeZO can effectively optimize non-differentiable objectives (e.g., maximizing accuracy or F1).MLC LLMhttps://github.com/mlc-ai/mlc-llmMLC LLM is a universal solution that allows any language models to be deployed natively on a diverse set of hardware backends and nativeapplications, plus a productive framework for everyone to further optimize model performance for their own use cases.Our mission is to enable everyone to develop, optimize and deploy AI models natively on everyone's devices.Everything runs locally with no server support and accelerated with local GPUs on your phone and laptops. Supported platforms include:iPhone, iPadMetal GPUs and Intel/ARM MacBooks;AMD, Intel and NVIDIA GPUs via Vulkan on Windows and Linux;NVIDIA GPUs via CUDA on Windows and Linux;WebGPU on browsers (through companion project WebLLM).PKU-Beaver 河狸 (Safe RLHF)https://github.com/PKU-Alignment/safe-rlhfhttps://mp.weixin.qq.com/s/ZpkgszXbisl5xf63EfTNjQ北京⼤学团队开源了名为 PKU-Beaver（河狸）项⽬，其开源地址为：https://github.com/PKU-Alignment/safe-rlhf。
该项⽬⾸次公开了 RLHF 所需的数据集、训练和验证代码，是⽬前⾸个开源的可复现的 RLHF 基准。
同时，为解决⼈类标注产⽣的偏⻅和歧视等不安全因素，北京⼤学团队⾸次提出了带有约束的价值对⻬技术 CVA（Constrained Value Alignment）。
该技术通过对标注信息进⾏细粒度划分，并结合带约束的安全强化学习⽅法，显著降低了模型的偏⻅和歧视，提⾼了模型的安全性。
Beaver使⽤GPT4进⾏Evaluation，结果表明，在原有性能保持不变的情况下，Beaver回复的安全性⼤幅度提升。
PaLM + RLHF (Pytorch)https://github.com/lucidrains/PaLM-rlhf-pytorchImplementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Maybe I'll add retrieval functionality too, à la RETRORL4LMshttps://github.com/allenai/RL4LMshttps://rl4lms.apps.allenai.org/A modular RL library to fine-tune language models to human preferencesWe provide easily customizable building blocks for training language models including implementations of on-policy algorithms, reward functions, metrics, datasets and LM based actor-critic policiesReinforcement Learning with Language Modelhttps://github.com/HarderThenHarder/transformers_tasks/tree/main/RLHF在这个项⽬中，我们将通过开源项⽬ trl 搭建⼀个通过强化学习算法（PPO）来更新语⾔模型（GPT-2）的⼏个示例，包括：基于中⽂情感识别模型的正向评论⽣成机器⼈（No Human Reward）基于⼈⼯打分的正向评论⽣成机器⼈（With Human Reward）基于排序序列（Rank List）训练⼀个奖励模型（Reward Model）排序序列（Rank List）标注平台SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compressionhttps://github.com/Vahe1994/SpQRhttps://arxiv.org/pdf/2306.03078.pdfhttps://mp.weixin.qq.com/s/819L-dY54BaVM1vub9OSpQSpQR 通过识别和隔离异常权重来⼯作，这些异常权重会导致特别⼤的量化误差，研究者将它们以更⾼的精度存储，同时将所有其他权重压缩到 3-4 位，在 LLaMA 和 Falcon LLMs 中实现了不到 1% 的困惑度相对准确率损失。
从⽽可以在单个 24GB 的消费级 GPU 上运⾏ 33B 参数的 LLM，⽽不会有任何性能下降，同时还能提⾼ 15% 的速度。
Scikit-LLM: Sklearn Meets Large Language Modelshttps://github.com/iryna-kondr/scikit-llmSeamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks.Transformer Reinforcement Learninghttps://github.com/lvwerra/trlWith trl you can train transformer language models with Proximal Policy Optimization (PPO). The library is built on top of the transformers library by Hugging Face. Therefore, pre-trained language models can be directly loaded via transformers. At this point most of decoderarchitectures and encoder-decoder architectures are supported.$Train_Transformers_with_INT4https://mp.weixin.qq.com/s/pyEJJ5AvQqfyncO7CA8eNAhttps://arxiv.org/abs/2306.11987https://github.com/xijiu9/Train_Transformers_with_INT4Quantizing the activation, weight, and gradient to 4-bit is promising to accelerate neural network training. However, existing 4-bit trainingmethods require custom numerical formats which are not supported by contemporary hardware. In this work, we propose a training method for transformers with all matrix multiplications implemented with the INT4 arithmetic. Training with an ultra-low INT4 precision is challenging. To achieve this, we carefully analyze the specific structures of activation and gradients in transformers to propose dedicated quantizers for them. For forward propagation, we identify the challenge of outliers and propose a Hadamard quantizer to suppress the outliers. For backpropagation, we leverage the structural sparsity of gradients by proposing bit splitting and leverage score sampling techniques to quantize gradients accurately. Our algorithm achieves competitive accuracy on a wide range of tasks including natural language understanding,machine translation, and image classification. Unlike previous 4-bit training methods, our algorithm can be implemented on the current generation of GPUs. Our prototypical linear operator implementation is up to 2.2 times faster than the FP16 counterparts and speeds up the training by up to 35.1%.Transformer Reinforcement Learning Xhttps://github.com/CarperAI/trlxtrlX is a distributed training framework designed from the ground up to focus on fine-tuning large language models with reinforcement learning using either a provided reward function or a reward-labeled dataset.Training support for Hugging Face models is provided by Accelerate-backed trainers, allowing users to fine-tune causal and T5-based language models of up to 20B parameters, such as facebook/opt-6.7b, EleutherAI/gpt-neox-20b, and google/flan-t5-xxl. For models beyond 20B parameters, trlX provides NVIDIA NeMo-backed trainers that leverage efficient parallelism techniques to scale effectively.vLLMhttps://github.com/vllm-project/vllmvLLM is a fast and easy-to-use library for LLM inference and serving.vLLM is fast with:State-of-the-art serving throughputEfficient management of attention key and value memory with PagedAttentionDynamic batching of incoming requestsOptimized CUDA kernelsvLLM is flexible and easy to use with:Seamless integration with popular HuggingFace modelsHigh-throughput serving with various decoding algorithms, including parallel sampling, beam search, and moreTensor parallelism support for distributed inferenceStreaming outputsOpenAI-compatible API server3 可参考的其它开源模型Cerebras（可商⽤）https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/https://huggingface.co/cerebras开源7个可商⽤GPT模型，含数据集和可直接下载的预训练模型权重: Cerebras 开源 7 个 GPT 模型，均可商⽤，参数量分别达到 1.11 亿、2.56 亿、5.9 亿、13 亿、27 亿、67 亿和 130 亿。
其中最⼤的模型参数量达到 130 亿，与 Meta 最近开源的 LLaMA-13B 相当。
该项⽬开源数据集和预训练模型权重，其中预训练模型权重⽂件⼤⼩近50G可直接下载，并且可⽤于商业和研究⽤途。
与此前的 GPT-3 模型相⽐，Cerebras开源的模型具有更⾼的可⽤性和透明度，研究⼈员和开发者可以使⽤少量数据对其进⾏微调，构建出⾼质量的⾃然语⾔处理应⽤。
ChatDoctor$https://github.com/Kent0n-Li/ChatDoctorhttps://arxiv.org/abs/2303.14070Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses. However, such language models have yet to be adapted for the medical domain, resulting in poor accuracy of responses and an inability to provide sound advice on medical diagnoses, medications, etc. To address this problem, we fine-tuned our ChatDoctor model based on 100k real-world patient-physician conversations from an online medical consultation site. Besides, we add autonomous knowledge retrieval capabilities to our ChatDoctor, for example, Wikipedia or a disease database as a knowledge brain. Byfine-tuning the LLMs using these 100k patient-physician conversations, our model showed significant improvements in understanding patients' needs and providing informed advice. The autonomous ChatDoctor model based on Wikipedia and Database Brain can access real-time and authoritative information and answer patient questions based on this information, significantly improving the accuracy of the model's responses, which shows extraordinary potential for the medical field with a low tolerance for error.Dolly 1&2（可商⽤）https://github.com/databrickslabs/dollyhttps://huggingface.co/databricks/dolly-v2-12bhttps://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.htmlWe show that anyone can take a dated off-the-shelf open source large language model (LLM) and give it magical ChatGPT-like instructionfollowing ability by training it in 30 minutes on one machine, using high-quality training data. Surprisingly, instruction-following does not seem to require the latest or largest models: our model is only 6 billion parameters, compared to 175 billion for GPT-3. We open source the code for our model (Dolly) and show how it can be re-created on Databricks. We believe models like Dolly will help democratize LLMs, transforming them from something very few companies can afford into a commodity every company can own and customize to improve their products.FinGPThttps://github.com/ai4finance-foundation/fingpthttps://arxiv.org/pdf/2306.06031v1.pdfhttps://mp.weixin.qq.com/s/A9euFin675nxGGciiX6rJQLarge language models (LLMs) have shown the potential of revolutionizing natural language processing tasks in diverse domains, sparkinggreat interest in finance. Accessing high-quality financial data is the first challenge for financial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken advantage of their unique data accumulation, such privileged access calls for an open-source alternative todemocratize Internet-scale financial data.In this paper, we present an open-source large language model, FinGPT, for the finance sector. Unlike proprietary models, FinGPT takes adata-centric approach, providing researchers and practitioners with accessible and transparent resources to develop their FinLLMs. We highlight the importance of an automatic data curation pipeline and the lightweight low-rank adaptation technique in building FinGPT. Furthermore, we showcase several potential applications as stepping stones for users, such as robo-advising, algorithmic trading, and low-codedevelopment. Through collaborative efforts within the open-source AI4Finance community, FinGPT aims to stimulate innovation, democratize FinLLMs, and unlock new opportunities in open finance.Falcon（可商⽤）https://mp.weixin.qq.com/s/mKx0ZiTB28khj4U7EVJiVwhttps://falconllm.tii.ae/https://huggingface.co/tiiuae/falcon-40bFalcon LLM is a foundational large language model (LLM) with 40 billion parameters trained on one trillion tokens. TII has now released Falcon LLM – a 40B model.The model uses only 75 percent of GPT-3’s training compute, 40 percent of Chinchilla’s, and 80 percent of PaLM-62B’s.Facebook/Meta LLaMA/LLaMA2https://github.com/facebookresearch/llamahttps://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/LLaMA1LLaMA: Open and Efficient Foundation Language ModelsWe introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.LLaMA2We are unlocking the power of large language models. Our latest version of Llama is now accessible to individuals, creators, researchers and businesses of all sizes so that they can experiment, innovate and scale their ideas responsibly.This release includes model weights and starting code for pretrained and fine-tuned Llama language models — ranging from 7B to 70B parameters.This repository is intended as a minimal example to load Llama 2 models and run inference. For more detailed examples leveraging HuggingFace, see llama-recipes.GALACTICAhttps://github.com/paperswithcode/galaihttps://arxiv.org/pdf/2211.09085.pdfhttps://galactica.org/GALACTICA is a general-purpose scientific language model. It is trained on a large corpus of scientific text and data. It can perform scientific NLP tasks at a high level, as well as tasks such as citation prediction, mathematical reasoning, molecular property prediction and proteinannotation. More information is available at galactica.org.Goar-7B for Arithmetic Taskshttps://mp.weixin.qq.com/s/_haINkHNV4bMszm9F41yXAhttps://arxiv.org/pdf/2305.14201.pdfhttps://github.com/liutiedong/goat在本⽂介绍了⼀种微调的语⾔模型：Goat。
不同于以往对算术计算的研究，该模型在 LLaMA上采⽤端到端监督指令微调范式，利⽤包含约100万个样本的综合⽣成数据集进⾏训练得到。
它⾮常擅⻓算术任务。
Goat 在初等算术（包括整数的加法、减法、乘法和除法）中实现了最先进的性能。
实验结果表明，仅通过监督微调⽽不应⽤任何特殊技术，「Goat模型能够在Zero-shot设置中以近乎完美的精度为⼤数加法和减法⽣成答案」。
这种出⾊的算术能⼒归因于 LLaMA 对数字的⼀致标记化，并表明这对于以前的 LLM 来说⼏乎是不可能实现的，例如 Bloom、OPT、GPT-NeoX 、Pythia等。
然⽽，该模型在⾯对乘除运算时遇到了很⼤的挑战。
为了克服这⼀挑战，本⽂提出了⼀种⽅法，即「将各种算术任务分为可学习和不可学习任务」，随后利⽤基本算术原理将不可学习任务（例如多位数乘法和除法）分解为⼀系列可学习任务。
本⽂⽅法确保促进模型学习的中间监督也很容易被⼈类理解，即通过模型微调在⽣成最终答案之前⽣成合适的CoT。
「本⽂⽅法⼤⼤优于 GPT-4 的⻓乘法和⻓除法」。
最终使⽤ BIG-bench (Srivastava et al., 2022) 算术⼦任务评估模型的性能，并对本⽂⽅法的有效性进⾏综合评估。
实验结果表明，该模型可以学习计算模式并将其泛化到看不⻅的数据，⽽不仅仅是纯粹权重记忆计算。
此外，Goat-7B 可以在24GB VRAM GPU上使⽤LoRA低秩适应技术进⾏训练，可以「很容易复现论⽂成果」。
HuggingChathttps://huggingface.co/chat/Making the community's best AI chat models available to everyone.Koala: A Dialogue Model for Academic Researchhttps://bair.berkeley.edu/blog/2023/04/03/koala/In this post, we introduce Koala, a chatbot trained by fine-tuning Meta’s LLaMA on dialogue data gathered from the web. We describe thedataset curation and training process of our model, and also present the results of a user study that compares our model to ChatGPT andStanford’s Alpaca. Our results show that Koala can effectively respond to a variety of user queries, generating responses that are often preferred over Alpaca, and at least tied with ChatGPT in over half of the cases.LongLLaMAhttps://mp.weixin.qq.com/s/XzaET7WfrNpOf-zdiSxrighttps://arxiv.org/pdf/2307.03170.pdfhttps://github.com/CStanKonrad/long_llamahttps://huggingface.co/syzymon/long_llama_3bThis repository contains the research preview of LongLLaMA, a large language model capable of handling long contexts of 256k tokens oreven more.LongLLaMA is built upon the foundation of OpenLLaMA and fine-tuned using the Focused Transformer (FoT) method. We release a smaller3B variant of the LongLLaMA model on a permissive license (Apache 2.0) and inference code supporting longer contexts on Hugging Face.Our model weights can serve as the drop-in replacement of LLaMA in existing implementations (for short context up to 2048 tokens). Additionally, we provide evaluation results and comparisons against the original OpenLLaMA models. Stay tuned for further updates.LLaMA复刻版OpenLLaMAhttps://github.com/openlm-research/open_llamaIn this repo, we release a permissively licensed open source reproduction of Meta AI's LLaMA large language model. In this release, we're releasing a public preview of the 7B OpenLLaMA model that has been trained with 200 billion tokens. We provide PyTorch and Jax weightsof pre-trained OpenLLaMA models, as well as evaluation results and comparison against the original LLaMA models. Stay tuned for our updates.Llama-X: Open Academic Research on Improving LLaMA to SOTA LLMhttps://github.com/AetherCortex/Llama-XThis is the repo for the Llama-X, which aims to:Progressively improve the performance of LLaMA to SOTA LLM with open-source community.Conduct Llama-X as an open academic research which is long-term, systematic and rigorous.Save the repetitive work of community and we work together to create more and faster increment.Lit-LLaMAhttps://github.com/Lightning-AI/lit-llamaLit-LLaMA is:Simple: Single-file implementation without boilerplate.Correct: Numerically equivalent to the original model.Optimized: Runs on consumer hardware or at scale.Open-source: No strings attached.MPT-7B（可商⽤）https://www.mosaicml.com/blog/mpt-7bhttps://huggingface.co/mosaicml/mpt-7bMPT-7B is a decoder-style transformer pretrained from scratch on 1T tokens of English text and code. This model was trained by MosaicML.MPT-7B is part of the family of MosaicPretrainedTransformer (MPT) models, which use a modified transformer architecture optimized for efficient training and inference.Introducing MPT-7B, the latest entry in our MosaicML Foundation Series. MPT-7B is a transformer trained from scratch on 1T tokens of text and code. It is open source, available for commercial use, and matches the quality of LLaMA-7B. MPT-7B was trained on the MosaicML platform in 9.5 days with zero human intervention at a cost of ~$200k. Starting today, you can train, finetune, and deploy your own private MPT models, either starting from one of our checkpoints or training from scratch. For inspiration, we are also releasing three finetuned models in addition to the base MPT-7B: MPT-7B-Instruct, MPT-7B-Chat, and MPT-7B-StoryWriter-65k+, the last of which uses a context lengthof 65k tokens!OpenGPThttps://github.com/CogStack/OpenGPTA framework for creating grounded instruction based datasets and training conversational domain expert Large Language Models (LLMs).NHS-LLM：A conversational model for healthcare trained using OpenGPT. All the medical datasets used to train this model were created using OpenGPT and are available below.Orcahttps://aka.ms/orca-lmhttps://arxiv.org/pdf/2306.02707.pdfhttps://mp.weixin.qq.com/s/RRdrSeI2ux5QE6MqJ8opSgRecent research has focused on enhancing the capability of smaller models through imitation learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the smallmodel's capability as they tend to learn to imitate the style, but not the reasoning process of LFMs. To address these challenges, we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMA's release policy to be published at this https URL), a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT. To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like theSAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve modelcapabilities and skills.OpenChatKithttps://www.together.xyz/blog/openchatkithttps://huggingface.co/spaces/togethercomputer/OpenChatKithttps://github.com/togethercomputer/OpenChatKitOpenChatKit uses a 20 billion parameter chat model trained on 43 million instructions and supports reasoning, multi-turn conversation, knowledge and generative answers.OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications. Thekit includes an instruction-tuned 20 billion parameter language model, a 6 billion parameter moderation model, and an extensible retrievalsystem for including up-to-date responses from custom repositories. It was trained on the OIG-43M training dataset, which was a collaboration between Together, LAION, and Ontocord.ai. Much more than a model release, this is the beginning of an open source project. We arereleasing a set of tools and processes for ongoing improvement with community contributions.Open-Assistanthttps://github.com/LAION-AI/Open-Assistanthttps://open-assistant.io/zhOpen Assistant is a project meant to give everyone access to a great chat based large language model.We believe that by doing this we will create a revolution in innovation in language. In the same way that stable-diffusion helped the world make art and images in new ways we hope Open Assistant can help improve the world by improving language itself.MedLLaMA-13B & PMC-LLaMA: Continue Training LLaMA on Medical Papershttps://github.com/chaoyi-wu/PMC-LLaMAhttps://huggingface.co/chaoyi-wu/PMC_LLAMA_7Bhttps://arxiv.org/abs/2304.14454We have release a new model MedLLaMA-13B finetuned with LLaMA-13B on some medical corpus, termed as MedLLaMA-13B. It have been proved to be more powerful than both LLaMA-13B and PMC-LLaMA, refering to our benchmark for detail comparison.RedPajama（可商⽤）https://www.together.xyz/blog/redpajamahttps://github.com/togethercomputer/RedPajama-DataRedPajama, a project to create leading open-source models, starts by reproducing LLaMA training dataset of over 1.2 trillion tokens.StableLMhttps://zhuanlan.zhihu.com/p/623542189https://github.com/Stability-AI/StableLMStableLM: Stability AI Language ModelsThis repository contains Stability AI's ongoing development of the StableLM series of language models and will be continuously updated with new checkpoints. The following provides an overview of all currently available models. More coming soon.StableVicunahttps://github.com/Stability-AI/StableLMStableVicuna基于⼩⽺驼Vicuna-13B的进⼀步指令微调和RLHF训练的版本。
Vicuna-13B是LLaMA-13B的⼀个指令微调模型。
Stanford Alpacahttps://crfm.stanford.edu/2023/03/13/alpaca.htmlhttps://alpaca-ai.ngrok.io/https://github.com/tatsu-lab/stanford_alpacaAlpaca: A Strong, Replicable Instruction-Following ModelAlWe introduce Alpaca 7B, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. On our preliminary evaluation of single-turn instruction following, Alpaca behaves qualitatively similarly to OpenAI’s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (<600$).UltraLM-13Bhttps://github.com/thunlp/UltraChatUltraLM is a series of chat language models trained on UltraChat. Currently, we have released the 13B version, which ranks #1 among open-source models and ranks #4 among all models on AlpacaEval Leaderboard. UltraLM-13B is based upon LLaMA-13B.This project aims to construct open-source, large-scale, and multi-round dialogue data powered by Turbo APIs to facilitate the construction of powerful language models with general conversational capability. In consideration of factors such as safeguarding privacy, we do not directly use any data available on the Internet as prompts. To ensure generation quality, two separate ChatGPT Turbo APIs are adopted in generation, where one plays the role of the user to generate queries and the other generates the response. We instruct the user model with carefully designed prompts to mimic human user behavior and call the two APIs iteratively. The generated dialogues undergo further post-processing and filtering.Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Qualityhttps://chat.lmsys.org/https://vicuna.lmsys.org/https://github.com/lm-sys/FastChatAn open platform for training, serving, and evaluating large language model based chatbots.Wombathttps://mp.weixin.qq.com/s/xoPKmOzjlNZ2qGdcKeGARwhttps://mp.weixin.qq.com/s/UI-ij5o43ct1efYoNVdQDghttps://arxiv.org/abs/2304.05302v1https://github.com/GanjinZero/RRHFThis is the repository for RRHF (Rank Response to align Human Feedback) and open-sourced language models Wombat. RRHF helps alignlarge language models with human perference easier.Reinforcement Learning from Human Feedback (RLHF) enables the alignment of large language models with human preference, improvingthe quality of interactions between humans and language models. Recent practice of RLHF uses PPO to enable the large language model optimization of such alignment. However, implementing PPO is non-trivial (where the training procedure requires interactive between policy,behavior policy, reward, value model) and it is also tedious to tuning many hyper-parameters. Our motivation is to simplify the alignment between language models with human preference, and our proposed paradigm RRHF (Rank Response from Human Feedback) can achieve such alignment as easily as conventional fine-tuning. It is simpler than PPO from the aspects of coding, model counts, and hyperparameters.XGen-7Bhttps://blog.salesforceairesearch.com/xgen/https://github.com/salesforce/xgenWe trained a series of 7B LLMs named XGen-7B with standard dense attention on up to 8K sequence length for up to 1.5T tokens. We alsofine tune the models on public-domain instructional data. The main take-aways are:On standard NLP benchmarks, XGen achieves comparable or better results when compared with state-of-the-art open-source LLMs (e.g. MPT, Falcon, LLaMA, Redpajama, OpenLLaMA) of similar model size.Our targeted evaluation on long sequence modeling benchmarks show benefits of our 8K-seq models over 2K- and 4K-seq models.XGen-7B archives equally strong results both in text (e.g., MMLU, QA) and code (HumanEval) tasks.Training cost of $150K on 1T tokens under Google Cloud pricing for TPU-v4.4 评价天秤（FlagEval）https://flageval.baai.ac.cn/#/home⼤语⾔评测体系及开放平台：构建“能⼒-任务-指标”三维评测框架，细粒度刻画模型的认知能⼒边界。
獬⾘（Xiezhi）Benchmarkhttps://arxiv.org/abs/2306.05783https://github.com/MikeGu721/XiezhiBenchmarkXiezhi是⼀个综合的、多学科的、能够⾃动更新的领域知识评估Benchmark。
Xiezhi包含了哲学、经济学、法学、教育学、⽂学、历史学、⾃然科学、⼯学、农学、医学、军事学、管理学、艺术学这13个学科⻔类，24万道学科题⽬，516个具体学科，249587道题⽬。
这 516 个学科以及分类⽅式源⾃中国教育部颁布的学科分类法。
作者从中国研究⽣⼊学考试中⼿动选择并注释了 20,000 道多选题，涵盖了这 516 个标签，以形成Xiezhi-Meta数据集。
Xiezhi-Meta被⽤来训练⼀个能够计算题⽬和学科标签之间相关性的标注模型。
作者们随后收集了来⾃不同考试的 150,000 个多项选择题，以及来⾃学术Survey的 70,000 个多项选择题，并使⽤标注模型对所有这些问题进⾏了注释。
为了⽅便进⾏实验，并能够有效地评估LLM对于跨学科知识的处理能⼒，作者们提出了Xiezhi-Specialty和Xiezhi-Interdiscipline，这两个数据集都提供了中英⽂的版本，并由 15,000 个更平衡、更不敏感、更不以中国为中⼼的多选题组成。
 Xiezhi-Specialty 包含可以使⽤单⼀领域的知识解决的问题，⽽ Xiezhi-Interdiscipline 包含需要来⾃多个领域的知识才能解决的问题。
C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Modelshttps://arxiv.org/abs/2305.08322https://cevalbenchmark.com/https://github.com/SJTU-LIT/cevalC-Eval is a comprehensive Chinese evaluation suite for foundation models. It consists of 13948 multi-choice questions spanning 52 diverse disciplines and four difficulty levels.HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Modelshttps://mp.weixin.qq.com/s/cuoO2V4X-GQOuWyA-e9BeQhttps://arxiv.org/abs/2305.11747https://github.com/RUCAIBox/HaluEval为了进⼀步研究⼤模型幻象的内容类型和⼤模型⽣成幻象的原因，本⽂提出了⽤于⼤语⾔模型幻象评估的基准⸺HaluEval。
我们基于现有的数据集，通过⾃动⽣成和⼿动标注的⽅式构建了⼤量的幻象数据组成HaluEval的数据集，其中包含特定于问答、对话、⽂本摘要任务的30000条样本以及普通⽤户查询的5000条样本。
在本⽂中，我们详细介绍了HaluEval数据集的构建过程，对构建的数据集进⾏了内容分析，并初步探索了⼤模型识别和减少幻象的策略。
KoLA: Carefully Benchmarking World Knowledge of Large Language Modelshttps://mp.weixin.qq.com/s/xVj1blhRtpO-Y1HgQ8Wl-Ahttps://arxiv.org/pdf/2306.09296.pdfhttps://kola.xlore.cnKoLA基于19个关注实体、概念和事件的任务。
参考了Bloom认知体系，KoLA从知识的记忆、理解、应⽤和创造4个层级，从深度⽽⾮⼴度去衡量⼤语⾔模型处理世界知识的能⼒。
实验结果表明，GPT-4虽然很强，但依然未能霸榜，在知识创造层次的测试中仅排第三名。
Multiscale Positive-Unlabeled Detection of AI-Generated Textshttps://mp.weixin.qq.com/s/KBN8TMwXD1bcE2X_dImXVghttps://arxiv.org/abs/2305.18149https://github.com/mindspore-lab/mindone/tree/master/examples/detect_chatgpthttps://github.com/YuchuanTian/AIGC_text_detectorRecent releases of Large Language Models (LLMs), e.g. ChatGPT, are astonishing at generating human-like texts, but they may get misused for fake scholarly texts, fake news, fake tweets, et cetera. Previous works have proposed methods to detect these multiscale AI-generated texts, including simple ML classifiers, pretrained-model-based training-agnostic methods, and finetuned language classification models.However, mainstream detectors are formulated without considering the factor of corpus length: shorter corpuses are harder to detect compared with longer ones for shortage of informative features. In this paper, a Multiscale Positive-Unlabeled (MPU) training framework is proposed to address the challenge of multiscale text detection. Firstly, we acknowledge the human-resemblance property of short machine texts, and rephrase text classification as a Positive-Unlabeled (PU) problem by marking these short machine texts as "unlabeled" during training. In this PU context, we propose the length-sensitive Multiscale PU Loss, where we use a recurrent model in abstraction to estimate positive priors of scale-variant corpuses. Additionally, we introduce a Text Multiscaling module to enrich training corpuses. Experiments showthat our MPU method augments detection performance on long AI-generated text, and significantly improves short-corpus detection of language model detectors. Language Models trained with MPU could outcompete existing detectors by large margins on multiscale AI-generated texts.PandaLMhttps://github.com/WeOpenML/PandaLMhttps://zhuanlan.zhihu.com/p/630173415https://mp.weixin.qq.com/s/HE6jez3G9aEO5qLkvwtKXgThis is the official repository for PandaLM: ReProducible and Automated Language Model Assessment.PandaLM aims to provide reproducible and automated comparisons between different large language models (LLMs). By giving PandaLM the same context, it can compare the responses of different LLMs and provide a reason for the decision, along with a reference answer. Thetarget audience for PandaLM may be organizations that have confidential data and research labs with limited funds that seek reproducibility. These organizations may not want to disclose their data to third parties or may not be able to afford the high costs of secret data leakage using third-party APIs or hiring human annotators. With PandaLM, they can perform evaluations without compromising data security or incurring high costs, and obtain reproducible results. To demonstrate the reliability and consistency of our tool, we have created a diverse human-annotated test dataset of approximately 1,000 samples, where the contexts and the labels are all created by humans. On our test dataset, PandaLM-7B has achieved 94% ChatGPT's evaluation ability in terms of accuracy. The papers and more features are coming soon.5 其它Alpaca-CoThttps://github.com/PhoebusSi/Alpaca-CoThttps://mp.weixin.qq.com/s/Q5Q3RpQ80XmpbfhSxq2R1QAn Instruction Fine-Tuning Platform with Instruction Data Collection and Unified Large Language Models InterfaceAlpaca-CoT项⽬旨在探究如何更好地通过instruction-tuning的⽅式来诱导LLM具备类似ChatGPT的交互和instruction-following能⼒。
为此，我们⼴泛收集了不同类型的instruction（尤其是Chain-of-Thought数据集），并基于LLaMA给出了深⼊细致的实证研究，以供未来⼯作参考。
据我们所知，我们是⾸个将CoT拓展进Alpaca的⼯作，因此简称为"Alpaca-CoT"。
Auto-GPThttps://github.com/torantulino/auto-gptAuto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven byGPT-4, chains together LLM "thoughts", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI.ChatPiXiuhttps://github.com/catqaq/ChatPiXiu我们是羡⻥智能【xianyu.ai】，主要成员是⼀群来⾃⽼和⼭下、⻄湖边上的咸⻥们，塘主叫作羡⻥，想在LLMs时代做点有意义的事！我们的⼝号是：做OpenNLP和OpenX！希望在CloseAI卷死我们之前退出江湖！也许有⼀天，等到GPT-X发布的时候，有⼈会说NLP不存在了，但是我们想证明有⼈曾经来过、热爱过！在以ChatGPT/GPT4为代表的LLMs时代，在被CloseAI卷死之前，我们发起了OpenNLP计划，宗旨是OpenNLP for everyone!ChatPiXiu项⽬为OpenNLP计划的第2个正式的开源项⽬，旨在Open ChatGPT for everyone！在以ChatGPT/GPT4为代表的LLMs时代，在被OpenAI卷死之前，做⼀点有意义的事情！未来有⼀天，等到GPT-X发布的时候，或许有⼈会说NLP不存在了，但是我们想证明有⼈曾来过！Gorillahttps://mp.weixin.qq.com/s/p9tx3q3Lpr4fNqdyxWhzyAgorilla.cs.berkeley.eduarxiv.org/abs/2305.15334https://github.com/ShishirPatil/gorilla/⼤型语⾔模型性能强⼤，但为了更好地⽤于解决实际问题，各式各样的 API 是必不可少的。
加利福尼亚⼤学伯克利分校和微软研究院造出了⼀只「⼤猩猩」Gorilla，该模型能根据⽤户输⼊的⾃然语⾔为⽤户选择合适的 API 来执⾏对应任务。
理论上讲，这个模型可以根据⽤户需求调⽤其它各种 AI 模型，因此 Gorilla 有望成为⼀个统御其它 AI 的 AI 模型。
该项⽬的代码、模型、数据和演示都已发布。
HuggingGPThttps://mp.weixin.qq.com/s/o51CmLt2JViJ4nsKfBJfwghttps://arxiv.org/pdf/2303.17580.pdfHuggingGPT利⽤ChatGPT作为控制器，连接HuggingFace社区中的各种AI模型，来完成多模态复杂任务。
这意味着，你将拥有⼀种超魔法，通过HuggingGPT，便可拥有多模态能⼒，⽂⽣图、⽂⽣视频、语⾳全能拿捏了。
LLMPruner：⼤语⾔模型裁剪⼯具https://mp.weixin.qq.com/s/u0UcCxzJOkF4fO_JI6ToQAhttps://github.com/yangjianxin1/LLMPruner在许多下游任务中，我们往往只需要使⽤到⼀两种语⾔，例如在中⽂场景中，⼀般只会⽤到中英⽂。
 所以我们可以对⼤语⾔模型的词表进⾏裁剪，只留下所需的部分词表，这样不仅能够充分保留模型的预训练知识，并且减少模型参数量，降低显存占⽤，提升训练速度，使⽤更少的显卡进⾏下游任务的finetune训练。
基于上述原因，笔者开发了LLMPruner项⽬，⽬前主要包含裁剪后的各种参数规模的Bloom模型。
对Bloom进⾏词表裁剪，保留常⽤的中英⽂token，词表由250880将⾄46145，缩减为原来的18.39%。
LLM-Pruner: On the Structural Pruning of Large Language Modelshttps://github.com/horseee/LLM-Prunerhttps://arxiv.org/abs/2305.11627https://mp.weixin.qq.com/s/feqFfy4n31eztoZfodMieQ在本⽂中，我们提出了 LLM-Pruner，⼀种⽤于⼤型语⾔模型的结构化剪枝⽅法。
LLM-Pruner 旨在以任务⽆关的⽅式压缩庞⼤的语⾔模型，同时尽量减少对原始训练语料库的依赖，并保留 LLM 的语⾔能⼒。
LLM-Pruner 通过迭代地检查模型中的每个神经元作为识别依赖组的触发器，从⽽构建 LLM 的依赖图。
随后，LLM-Pruner 使⽤参数级和权重级估计来评估这些组的重要性。
最后，我们利⽤ LoRA 对被剪枝模型进⾏快速恢复和调整。
我们使⽤多个 zero-shot 数据集评估了 LLM-Pruner 在三个不同模型（LLaMA，Vicuna 和 ChatGLM）上的有效性。
我们的实验结果表明，LLM-Pruner 成功地剪枝了模型，在保留 zero-shot 能⼒的同时减轻了计算负担。
LLM for Recommendation Systemshttps://github.com/WLiK/LLM4Rechttps://arxiv.org/abs/2305.19860https://mp.weixin.qq.com/s/WCUjCahiak4STbb0QjJInQLarge Language Models (LLMs) have emerged as powerful tools in the field of Natural Language Processing (NLP) and have recently gained significant attention in the domain of Recommendation Systems (RS). These models, trained on massive amounts of data using self-supervised learning, have demonstrated remarkable success in learning universal representations and have the potential to enhance various aspects of recommendation systems by some effective transfer techniques such as fine-tuning and prompt tuning, and so on. The crucial aspect of harnessing the power of language models in enhancing recommendation quality is the utilization of their high-quality representations of textual features and their extensive coverage of external knowledge to establish correlations between items and users. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey presents a taxonomy that categorizes thesemodels into two major paradigms, respectively Discriminative LLM for Recommendation (DLLM4Rec) and Generative LLM for Recommendation (GLLM4Rec), with the latter being systematically sorted out for the first time. Furthermore, we systematically review and analyze existing LLM-based recommendation systems within each paradigm, providing insights into their methodologies, techniques, and performance. Additionally, we identify key challenges and several valuable findings to provide researchers and practitioners with inspiration.Self-Instructhttps://github.com/yizhongw/self-instructhttps://arxiv.org/abs/2212.10560Self-Instruct is a framework that helps language models improve their ability to follow natural language instructions. It does this by using the model's own generations to create a large collection of instructional data. With Self-Instruct, it is possible to improve the instruction-following capabilities of language models without relying on extensive manual annotation.ToolBenchhttps://github.com/OpenBMB/ToolBenchhttps://arxiv.org/pdf/2304.08354.pdfhttps://mp.weixin.qq.com/s/DuoQJj1OBl5iFPvjidDiCgThis project aims to construct open-source, large-scale, high-quality instruction tuning SFT data to facilitate the construction of powerfulLLMs with general tool-use capability. We provide the dataset, the corresponding training and evaluation scripts, and a capable model ToolLLaMA fine-tuned on ToolBench.Wanda (Pruning by Weights and activations)https://github.com/locuslab/wandahttps://mp.weixin.qq.com/s/UoQLCQiFnKZUQPedDM_MCQhttps://arxiv.org/pdf/2306.11695.pdfA Simple and Effective Pruning Approach for Large Language ModelsAs their size increases, Large Languages Models (LLMs) are natural candidates for network pruning methods: approaches that drop a subset of network weights while striving to preserve performance. Existing methods, however, require either retraining, which is rarely affordable for billion-scale LLMs, or solving a weight reconstruction problem reliant on second-order information, which may also be computationally expensive. In this paper, we introduce a novel, straightforward yet effective pruning method, termed Wanda (Pruning by Weights and activations), designed to induce sparsity in pretrained LLMs. Motivated by the recent observation of emergent large magnitude features in LLMs, our approach prune weights with the smallest magnitudes multiplied by the corresponding input activations, on a per-output basis. Notably, Wanda requires no retraining or weight update, and the pruned LLM can be used as is. We conduct a thorough evaluation of our method on LLaMA across various language benchmarks. Wanda significantly outperforms the established baseline of magnitude pruning and competes favorably against recent methods involving intensive weight update.本⽂档由⽹友提供，仅限参考学习，如有不妥或产⽣版权问题，请联系我们及时删除。
 客服请联系：31998589@qq.com 微信：skillupvip这个创作者的更多内容查看更多检索增强⽣成 (RAG):What, Why a 为什么说数智化可以帮助中⼩企业 ChatGPT提示⼯程5篇合集 - 吴恩nd How? 降本增效 ? 达和OpenAI出品评论0 评论关于我们 ⽤户协议京ICP备20027199号-1